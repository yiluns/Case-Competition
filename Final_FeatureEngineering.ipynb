{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cluster\n",
    "from sklearn.decomposition import PCA\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpainton/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (79) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_csv(\"data/2020_Competition_Holdout.csv\")\n",
    "health = original.copy()\n",
    "original = original.set_index('person_id_syn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapStringVariables(data):\n",
    "    \"\"\"\n",
    "    Reorganizes columns to alphabetical order, Maps all string variables into new groups.  Prepares string values\n",
    "    to be turned into dummy variables. \n",
    "    \n",
    "    One input:\n",
    "    \n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns pandas data frame Variables remapped to prepare to create dummy variables \n",
    "    \"\"\"\n",
    "    data = data.reindex(sorted(data.columns), axis = 1)\n",
    "    data['cons_cmys'] = data['cons_cmys'].map({'0':'Unknown',\n",
    "                                                          '1': 'Less Than High School',\n",
    "                                                          '2': 'Less Than High School', \n",
    "                                                          '3': 'High School Diploma',\n",
    "                                                          '4': 'Some College', \n",
    "                                                          '5': 'Associate Degree',\n",
    "                                                          '6': 'Bachelors Degree',\n",
    "                                                          '7': 'Graduate Degree', \n",
    "                                                          '8': 'Professional School Degree',\n",
    "                                                          '9': 'Doctorate Degree'})\n",
    "    data['cons_cmys'].fillna('Unknown', inplace = True)\n",
    "    data['cons_hhcomp'] = data['cons_hhcomp'].map({'A':'Min Two People, Children',\n",
    "                                                          'C': 'Min Two People, Children',\n",
    "                                                          'D': 'Min Two People, No Children', \n",
    "                                                          'E': 'Min Two People, Children',\n",
    "                                                          'F': 'Min Two People, No Children', \n",
    "                                                          'G': 'Min Two People, Children',\n",
    "                                                          'H': 'Min Two People, No Children',\n",
    "                                                          'B': 'Min Two People, No Children', \n",
    "                                                          'I': 'One Person, Children',\n",
    "                                                          'J': 'One Person, No Children',\n",
    "                                                          'K': 'One Person, Children', \n",
    "                                                          'L': 'One Person, No Children',\n",
    "                                                          'U': 'Unknown'})\n",
    "    data['cons_hhcomp'].fillna('Unknown', inplace = True)\n",
    "    data['cms_ra_factor_type_cd'] = data['cms_ra_factor_type_cd'].map({'CN': 'CN',\n",
    "                                                                      'CP': 'CP',\n",
    "                                                                      'E': 'E',\n",
    "                                                                      'CF': 'CF',\n",
    "                                                                      'D':'D',\n",
    "                                                                      '1': 'Other',\n",
    "                                                                      'C2' : 'Other',\n",
    "                                                                      'I': 'Other',\n",
    "                                                                      'SE': 'Other',\n",
    "                                                                      '*': 'Other'})\n",
    "\n",
    "    data['cms_ra_factor_type_cd'].fillna('Unknown', inplace = True)\n",
    "    data['cons_homstat'] = data['cons_homstat'].map({'P': 'Homeowner',\n",
    "                                                                 'R': 'Renter',\n",
    "                                                                 'T': 'Renter',\n",
    "                                                                 'U': 'Unknown',\n",
    "                                                                 'Y': 'Homeowner'})\n",
    "    data['cons_homstat'].fillna('Unknown', inplace = True)\n",
    "    \n",
    "    data['sex_cd'] = data['sex_cd'].map({'M': 0, 'F': 1})\n",
    "    for i in range(203, 212):\n",
    "        data.iloc[:,i] = data.iloc[:,i].map({'Y': 1, 'N': 0})\n",
    "        \n",
    "    data['lang_spoken_cd'] = data['lang_spoken_cd'].map({'E': 'ENG', 'ENG': 'ENG', 'SPA': 'SPA'})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropMajorityNAcolumns(data, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Drops all columns from data that have a certain NA percentage of values above the threshold. \n",
    "    \n",
    "    Two Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "    threshold (default = 0.5): a non-negative value (from 0.0 to 1.0) that represents a threshold percentage for \n",
    "    which columns to drop\n",
    "    \n",
    "    Returns pandas DataFrame with dropped columns\n",
    "    \"\"\"\n",
    "    \n",
    "    for column in data.columns:\n",
    "        if (data[column].isna().sum() / len(data[column])) >= threshold:\n",
    "            data.drop(column, inplace = True, axis = 1)\n",
    "            print(\"Dropped: \", column)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnBinning(data):\n",
    "    \"\"\"\n",
    "    Groups columns into specific bins, removes their original columns\n",
    "    \n",
    "    One Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "\n",
    "    Returns pandas DataFrame with new columns, removes columns that are not of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    ccsp_columns = ['ccsp_014_ind', 'ccsp_021_ind', 'ccsp_034_ind', 'ccsp_060_ind', 'ccsp_080_ind', 'ccsp_107_ind',\n",
    "                   'ccsp_125_ind', 'ccsp_204_ind', 'ccsp_212_ind', 'ccsp_242_ind']\n",
    "    \n",
    "    data['cons_n2mob'] = round(data['cons_n2mob'], 2) / 100\n",
    "    data['cons_n2pbl'] = round(data['cons_n2pbl'], 2) / 100\n",
    "    data['cons_n2pmv'] = round(data['cons_n2pmv'], 2) / 100\n",
    "    \n",
    "    \n",
    "    for ccsp_column in ccsp_columns: \n",
    "            data.loc[data[ccsp_column] == 1, 'ccsp_extra_group'] = 1\n",
    "            data.drop(ccsp_column, inplace = True, axis = 1)\n",
    "    data['ccsp_extra_group'].fillna(0, inplace = True)\n",
    "            \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def columnsToDrop(data): \n",
    "    \"\"\"\n",
    "    Drops all columns that are not going to be used in the model.  \n",
    "    \n",
    "    One Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "\n",
    "    Returns pandas DataFrame with dropped columns\n",
    "    \"\"\"\n",
    "    \n",
    "    columns_drop = ['lab_bnp_abn_result_ind', 'lab_hba1_c_abn_result_ind', 'med_ip_ltach_admit_ct_pmpm',\n",
    "                   'med_ip_ltach_admit_days_pmpm', 'med_ip_maternity_admit_ct_pmpm', 'med_ip_maternity_admit_days_pmpm',\n",
    "                   'med_ip_mhsa_admit_ct_pmpm', 'med_ip_mhsa_admit_days_pmpm',\n",
    "                    'src_platform_cd']\n",
    "    \n",
    "    columns_drop += [\"submcc_ano_mus_pmpm_ct\", \"submcc_ano_othr_pmpm_ct\",\"submcc_ben_lymp_pmpm_ct\",\"submcc_ben_ner_pmpm_ct\", \n",
    "                      \"submcc_brn_acc_pmpm_ct\",\"submcc_cad_fh/ho_pmpm_ct\",\"submcc_cad_ptca_pmpm_ct\", \"submcc_can_brst_pmpm_ct\",\n",
    "                     \"submcc_can_leuk_pmpm_ct\",\"submcc_can_ner_pmpm_ct\",\n",
    "                     \"submcc_gus_othr_pmpm_ct\",\"submcc_hdz_arrh_pmpm_ct\",\"submcc_hdz_it_i_pmpm_ct\",\"submcc_hdz_surg_pmpm_ct\",\n",
    "                      \"submcc_hdz_valv_pmpm_ct\",\"submcc_hiv_kapo_pmpm_ct\",\"submcc_hiv_pcp_pmpm_ct\",\"submcc_inf_men_pmpm_ct\",\n",
    "                      \"submcc_inf_myco_pmpm_ct\",\"submcc_inj_comp_pmpm_ct\",\"submcc_mus_othr_pmpm_ct\",\"submcc_neo_fh/ho_pmpm_ct\",\n",
    "                    \"submcc_pre_care_pmpm_ct\", \"submcc_pre_del_pmpm_ct\",\"submcc_pre_l/d_pmpm_ct\",\"submcc_pre_mul_pmpm_ct\",\n",
    "                    \"submcc_pre_ect_pmpm_ct\",\"submcc_pre_othr_pmpm_ct\",\"submcc_rar_als_pmpm_ct\",\n",
    "                    \"submcc_rar_cf_pmpm_ct\",\"submcc_rar_drm_pmpm_ct\",\"submcc_rar_mg_pmpm_ct\",\"submcc_rar_othr_pmpm_ct\",\n",
    "                    \"submcc_rar_pol_pmpm_ct\",\"submcc_rar_sca_pmpm_ct\",\"submcc_rar_scl_pmpm_ct\",\"submcc_rsk_an_pmpm_ct\",\n",
    "                    \"submcc_rsk_fh/h_pmpm_ct\",\"submcc_rsk_othr_pmpm_ct\",\"submcc_rsk_pcos_pmpm_ct\",\n",
    "                      \"submcc_trm_fxu_pmpm_ct\",\"submcc_trm_fxul_pmpm_ct\",\"submcc_vco_end_pmpm_ct\"]\n",
    "    \n",
    "    columns_drop += [\"submcc_ano_mus_ind\", \"submcc_ano_othr_ind\",\"submcc_ben_lymp_ind\",\"submcc_ben_ner_ind\", \n",
    "                      \"submcc_brn_acc_ind\",\"submcc_cad_fh/ho_ind\",\"submcc_cad_ptca_ind\", \"submcc_can_brst_ind\",\n",
    "                     \"submcc_can_leuk_ind\",\"submcc_can_ner_ind\",\n",
    "                     \"submcc_gus_othr_ind\",\"submcc_hdz_arrh_ind\",\"submcc_hdz_it_i_ind\",\"submcc_hdz_surg_ind\",\n",
    "                      \"submcc_hdz_valv_ind\",\"submcc_hiv_kapo_ind\",\"submcc_hiv_pcp_ind\",\"submcc_inf_men_ind\",\n",
    "                      \"submcc_inf_myco_ind\",\"submcc_inj_comp_ind\",\"submcc_mus_othr_ind\",\"submcc_neo_fh/ho_ind\",\n",
    "                    \"submcc_pre_care_ind\", \"submcc_pre_del_ind\",\"submcc_pre_l/d_ind\",\"submcc_pre_mul_ind\",\n",
    "                    \"submcc_pre_ect_ind\",\"submcc_pre_othr_ind\",\"submcc_rar_als_ind\",\n",
    "                    \"submcc_rar_cf_ind\",\"submcc_rar_drm_ind\",\"submcc_rar_mg_ind\",\"submcc_rar_othr_ind\",\n",
    "                    \"submcc_rar_pol_ind\",\"submcc_rar_sca_ind\",\"submcc_rar_scl_ind\",\"submcc_rsk_an_ind\",\n",
    "                    \"submcc_rsk_fh/h_ind\",\"submcc_rsk_othr_ind\",\"submcc_rsk_pcos_ind\",\n",
    "                      \"submcc_trm_fxu_ind\",\"submcc_trm_fxul_ind\",\"submcc_vco_end_ind\"]\n",
    "    \n",
    "    for columns in columns_drop:\n",
    "        data.drop(columns, inplace = True, axis = 1)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LabelEncoding(data): \n",
    "    '''\n",
    "    Encodes Categorical data to levels to prepare for machine learning model \n",
    "    \n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    lb_make = LabelEncoder()\n",
    "    \n",
    "    data['rucc_category'] = lb_make.fit_transform(data['rucc_category'])\n",
    "    data['state_cd'] = lb_make.fit_transform(data['state_cd'])\n",
    "    data['zip_cd'] = lb_make.fit_transform(data['zip_cd'])\n",
    "    data['cnty_cd'] = lb_make.fit_transform(data['cnty_cd'])\n",
    "    \n",
    "    pdc = ['pdc_ast', 'pdc_cvd', 'pdc_dep', 'pdc_dia', 'pdc_hf', 'pdc_ht', 'pdc_lip', 'pdc_ost']\n",
    "    for p in pdc: \n",
    "        data.loc[data[p] == 1.1, p] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def betosEngineering(data):\n",
    "    '''\n",
    "    Creates new features for three different groups in Betos: common, uncommon, and critical.  Sums all the claims\n",
    "    based on these three groups and returns the new columns. Afterwards, drops the old betos columns (pmpm_ct)\n",
    "    \n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    common_visits = ['betos_m1b_pmpm_ct', 'betos_o1b_pmpm_ct', 'betos_o1e_pmpm_ct', 'betos_o1g_pmpm_ct',\n",
    "                'betos_t1a_pmpm_ct', 'betos_t1b_pmpm_ct', 'betos_t1e_pmpm_ct', 'betos_t1h_pmpm_ct',\n",
    "                'betos_t2a_pmpm_ct', 'betos_y2_pmpm_ct']\n",
    "    uncommon = ['betos_d1c_pmpm_ct', 'betos_m5b_pmpm_ct', 'betos_m5c_pmpm_ct', 'betos_m5d_pmpm_ct']\n",
    "    critical = ['betos_d1d_pmpm_ct', 'betos_m2c_pmpm_ct', 'betos_o1a_pmpm_ct']\n",
    "\n",
    "    data['betos_common_visits_pmpm_ct'] = data[common_visits].sum(axis = 1)\n",
    "    data['betos_uncommon_visits_pmpm_ct'] = data[uncommon].sum(axis = 1)\n",
    "    data['betos_critical_visits_pmpm_ct'] = data[critical].sum(axis = 1)\n",
    "    \n",
    "    total = common_visits + uncommon + critical\n",
    "    \n",
    "    pca = PCA(n_components = 7)\n",
    "    pc = pca.fit_transform(data[total])\n",
    "    \n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_betos', 'PCA2_betos', 'PCA3_betos', \n",
    "                                                  'PCA4_betos', 'PCA5_betos', 'PCA6_betos',\n",
    "                                                  'PCA7_betos'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    labels = range(1,101)\n",
    "    betos_list = []\n",
    "    for single in total: \n",
    "        name = single + \"_rank\"\n",
    "        data[name] = pd.qcut(data[single].rank(method = 'first'), q = 100, labels = labels)\n",
    "        betos_list.append(name)\n",
    "        data[name] = data[name].astype(int)\n",
    "    \n",
    "    data['Betos_Score'] = data[betos_list].sum(axis=1)\n",
    "    data['Betos_AVG_Score'] = Standardize(data['Betos_Score'])\n",
    "    data['Betos_Score'] = data[betos_list].mean(axis=1)\n",
    "    data['Betos_AVG_Score'] = Standardize(data['Betos_Score'])\n",
    "    data['est_age_std'] = Standardize(data['est_age'])\n",
    "\n",
    "    model_betos = cluster.KMeans(n_clusters = 20)\n",
    "    data['Betos_Score_clusters'] = model_betos.fit_predict(data[['Betos_Score', 'est_age_std']])\n",
    "\n",
    "    for column in total:\n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def medEngineering(data):\n",
    "    '''\n",
    "    Creates new feature based on total admitted days for non-BH related claims. \n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    med_admit = ['med_ip_acute_admit_days_pmpm', 'med_ip_rehab_admit_days_pmpm', 'med_ip_snf_admit_days_pmpm']\n",
    "    \n",
    "    data['med_admit_days'] = data[med_admit].sum(axis = 1)\n",
    "    for column in med_admit:\n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creditDataEngineering(data): \n",
    "    '''\n",
    "    Creates new features based on credit data information\n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    from sklearn import cluster\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    credit_bal_general = ['credit_bal_autobank', 'credit_bal_autofinance', 'credit_bal_consumerfinance']\n",
    "    \n",
    "    credit_bal_new = ['credit_bal_agencyfirstmtg_new', 'credit_bal_autobank_new', 'credit_bal_autofinance_new',\n",
    "                     'credit_bal_consumerfinance_new','credit_bal_mtgcredit_new']\n",
    "    \n",
    "    credit_bal_dpd = ['credit_bal_1stmtg_30to59dpd', 'credit_bal_1stmtg_60to89dpd', 'credit_bal_1stmtgcredit_60dpd',\n",
    "                     'credit_bal_agencyfirstmtg_60dpd', 'credit_bal_heloc_60dpd', 'credit_bal_mtg_90to119dpd',\n",
    "                     'credit_bal_nonagn1stmorg_30to59dpd', 'credit_bal_nonagn1stmorg_60to89dpd', \n",
    "                     'credit_bal_nonagn1stmorg_90to119dp', 'credit_bal_nonagnfirstmtg_60dpd', 'credit_bal_nonmtgcredit_60dpd',\n",
    "                     'credit_bal_studentloan_60dpd']\n",
    "    \n",
    "    credit_bal_overage = ['credit_bal_1stmtg_collections', 'credit_bal_1stmtg_severederog', 'credit_bal_agency1stmorg_collectio',\n",
    "                         'credit_bal_bankcard_severederog', 'credit_bal_heloc_severederog', 'credit_bal_mtg_bankruptcy',\n",
    "                         'credit_bal_mtg_severederog', 'credit_bal_nonagn1stmorg_bankruptc', 'credit_bal_nonagn1stmorg_collectio']\n",
    "\n",
    "    credit_num_new = ['credit_num_1stmtgcredit_new', 'credit_num_agencyfirstmtg_new', 'credit_num_autobank_new',\n",
    "                 'credit_num_autofinance_new', 'credit_num_consumerfinance_new', 'credit_num_mtgcredit_new']\n",
    "\n",
    "    credit_num_general = ['credit_num_1stmtgcredit', 'credit_num_agencyfirstmtg', 'credit_num_autobank', \n",
    "                         'credit_num_autofinance', 'credit_num_consumerfinance', 'credit_num_studentloan']\n",
    "\n",
    "    credit_num_dpd = ['credit_num_1stmtg_30to59dpd', 'credit_num_1stmtg_60to89dpd', 'credit_num_agencyfirstmtg_60dpd',\n",
    "                      'credit_num_mtg_60to89dpd', 'credit_num_mtg_90to119dpd', 'credit_num_nonagn1stmorg_30to59dpd', \n",
    "                      'credit_num_nonagn1stmorg_60to89dpd', 'credit_num_nonagn1stmorg_90to119dp',\n",
    "                      'credit_num_nonmtgcredit_60dpd', 'credit_num_studentloan_60dpd', 'credit_num_heloc_60dpd']\n",
    "\n",
    "    credit_num_danger = ['credit_num_1stmtg_bankruptcy', 'credit_num_1stmtg_collections', 'credit_num_1stmtg_severederog',\n",
    "                         'credit_num_agency1stmorg_collectio', 'credit_num_bankcard_severederog', 'credit_num_heloc_severederog',\n",
    "                         'credit_num_mtg_collections', 'credit_num_mtg_severederog', 'credit_num_nonagn1stmorg_bankruptc',\n",
    "                         'credit_num_nonagn1stmorg_collectio']\n",
    "    \n",
    "    credit_hh_new = ['credit_hh_1stmtgcredit_new', 'credit_hh_agencyfirstmtg_new', 'credit_hh_autobank_new',\n",
    "                 'credit_hh_autofinance_new', 'credit_hh_consumerfinance_new', 'credit_hh_mtgcredit_new']\n",
    "\n",
    "    credit_hh_dpd = ['credit_hh_bankcardcredit_60dpd', 'credit_hh_nonmtgcredit_60dpd',\n",
    "                     'credit_hh_studentloan_60dpd']\n",
    "    \n",
    "    percent_balance = ['credit_prcnt_agencyfirstmtg', 'credit_prcnt_autobank',\n",
    "                      'credit_prcnt_mtgcredit', 'credit_prcnt_nonagnfirstmtg']\n",
    "    \n",
    "    credit_hh_clusters = ['credit_hh_1stmtg_severederog', 'credit_hh_1stmtgcredit', 'credit_hh_1stmtgcredit_new',\n",
    "                          'credit_hh_agencyfirstmtg', 'credit_hh_agencyfirstmtg_new', 'credit_hh_autobank',\n",
    "                          'credit_hh_autobank_new', 'credit_hh_autofinance', 'credit_hh_autofinance_new',\n",
    "                          'credit_hh_bankcard_severederog', 'credit_hh_bankcardcredit_60dpd',\n",
    "                          'credit_hh_consumerfinance', 'credit_hh_consumerfinance_new', 'credit_hh_mtg_severederog',\n",
    "                          'credit_hh_mtgcredit_new', 'credit_hh_nonagnfirstmtg', 'credit_hh_nonmtgcredit_60dpd',\n",
    "                          'credit_hh_studentloan', 'credit_hh_studentloan_60dpd', 'credit_hh_totalallcredit_bankruptcy',\n",
    "                          'credit_hh_totalallcredit_collections', 'credit_hh_totalallcredit_severederog']\n",
    "    \n",
    "    age_accounts = ['credit_minmob_1stmtgcredit', 'credit_minmob_agencyfirstmtg', 'credit_minmob_mtgcredit']\n",
    "    \n",
    "    credit_balance = ['credit_bal_totalallcredit_60dpd', 'credit_bal_totalallcredit_60to89dpd', 'credit_bal_totalallcredit_90to119dpd'\n",
    "                      'credit_bal_totalallcredit_new']\n",
    "    \n",
    "    credit_bal_clusters = credit_bal_general + credit_bal_dpd + credit_bal_overage + credit_bal_new\n",
    "    credit_num_clusters = credit_num_new + credit_num_general + credit_num_dpd + credit_num_danger\n",
    "    \n",
    "    data['average_minmob_percent_of_age'] = round(data[age_accounts].mean(axis = 1) / data['est_age'], 2)\n",
    "    data.loc[data['average_minmob_percent_of_age'] > 1, 'average_minmob_percent_of_age'] = 1\n",
    "    \n",
    "    data['average_percent_balance_total'] = round(data[percent_balance].sum(axis = 1) / 4, 1)\n",
    "    \n",
    "    data['credit_num_new'] = data[credit_num_new].sum(axis = 1)\n",
    "    data['credit_num_general'] = data[credit_num_general].sum(axis = 1)\n",
    "    data['credit_num_dpd'] = data[credit_num_dpd].sum(axis = 1)\n",
    "    data['credit_num_overage'] = data[credit_num_danger].sum(axis = 1)\n",
    "    \n",
    "    data['credit_hh_new_average'] = data[credit_hh_new].mean(axis = 1)\n",
    "    data['credit_hh_dpd_average'] = data[credit_hh_dpd].mean(axis = 1)\n",
    "    \n",
    "    data['credit_weighted_pct_dpd_overdue'] = 0.3 * data['credit_hh_totalallcredit_bankruptcy'] +\\\n",
    "                                              0.25 * data['credit_hh_totalallcredit_collections'] +\\\n",
    "                                              0.25 * data['credit_hh_totalallcredit_severederog'] +\\\n",
    "                                              0.2 * (data[credit_hh_dpd].sum(axis = 1))\n",
    "    \n",
    "    credit_all = credit_bal_general + credit_bal_dpd + credit_bal_overage + credit_bal_new\n",
    "    credit_bal_num = ['credit_num_new', 'credit_num_general', 'credit_num_dpd', 'credit_num_overage']\n",
    "    credit_total = data[credit_all].sum(axis = 1)\n",
    "    credit_num_total = data[credit_bal_num].sum(axis = 1)\n",
    "    \n",
    "    data['credit_weighted_pct_dpd_overdue'] = data['credit_weighted_pct_dpd_overdue'] / 100\n",
    "    \n",
    "    data['credit_financial_index'] = 0.075 * data[credit_bal_general].sum(axis = 1) / credit_total +\\\n",
    "                                       0.075 * data['credit_num_general'] / credit_num_total +\\\n",
    "                                       0.25 * data[credit_bal_dpd].sum(axis = 1) / credit_total +\\\n",
    "                                       0.05 * data['credit_num_dpd'] / credit_num_total +\\\n",
    "                                       0.30 * data[credit_bal_overage].sum(axis = 1) / credit_total +\\\n",
    "                                       0.10 * data['credit_num_overage'] / credit_num_total +\\\n",
    "                                       0.075 * data[credit_bal_new].sum(axis = 1) / credit_total +\\\n",
    "                                       0.075 * data['credit_num_new'] / credit_num_total     \n",
    "    data['credit_financial_index'] = (data['credit_financial_index'] - data['credit_financial_index'].min()) /\\\n",
    "                                      (data['credit_financial_index'].max() - data['credit_financial_index'].min())\n",
    "            \n",
    "    data['credit_total_new'] = data[credit_bal_new].sum(axis = 1)\n",
    "    data['credit_dpd_exposure'] = data['credit_num_dpd'] * data[credit_bal_dpd].sum(axis = 1)\n",
    "    data['credit_overage_exposure'] = data['credit_num_overage'] * data[credit_bal_overage].sum(axis = 1)\n",
    "    \n",
    "    data['default_risk'] = 0.2 * data['credit_dpd_exposure'] / np.log(credit_total + 1) +\\\n",
    "                            0.75 * data['credit_overage_exposure'] / np.log(credit_total + 1) +\\\n",
    "                            0.05 * data['credit_total_new'] / np.log(credit_total + 1) \n",
    "    data.loc[data['default_risk'] > 4, 'default_risk'] = 4\n",
    "    data['default_risk'] = (data['default_risk'] - data['default_risk'].min()) / (data['default_risk'].max() - data['default_risk'].min())\n",
    "    data['default_risk'].fillna(0, inplace = True)\n",
    "    \n",
    "    #Credit Balance Clustering Engineering\n",
    "    labels = range(1,101)\n",
    "    balance = []\n",
    "    for columns in credit_bal_clusters: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 100, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        balance.append(name)\n",
    "    pca = PCA(n_components = 12)\n",
    "    pc = pca.fit_transform(data[credit_bal_clusters])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_creditbal', 'PCA2_creditbal', 'PCA3_creditbal', \n",
    "                                                  'PCA4_creditbal', 'PCA5_creditbal', 'PCA6_creditbal',\n",
    "                                                  'PCA7_creditbal', 'PCA8_creditbal', 'PCA9_creditbal',\n",
    "                                                  'PCA10_creditbal', 'PCA11_creditbal', 'PCA12_creditbal'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "\n",
    "    data['Credit_Bal_Score'] = data[balance].sum(axis=1)\n",
    "    data['Credit_Bal_AVG_Score'] = data[balance].mean(axis=1)\n",
    "    data['Credit_Bal_Score'] = Standardize(data['Credit_Bal_Score'])\n",
    "    data['Credit_Bal_AVG_Score'] = Standardize(data['Credit_Bal_AVG_Score'])\n",
    "    data['default_risk_std'] = Standardize(data['default_risk'])\n",
    "    model_bal = cluster.KMeans(n_clusters = 30)\n",
    "    data['Credit_Bal_Score_clusters'] = model_bal.fit_predict(data[['Credit_Bal_Score', 'default_risk_std']])\n",
    "    \n",
    "    #Credit Number Clustering Engineering \n",
    "    number = []\n",
    "    for columns in credit_num_clusters: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 100, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        number.append(name)\n",
    "        \n",
    "    pca = PCA(n_components = 5)\n",
    "    pc = pca.fit_transform(data[credit_bal_clusters])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_creditnum', 'PCA2_creditnum', 'PCA3_creditnum', \n",
    "                                                  'PCA4_creditnum', 'PCA5_creditnum'])\n",
    "    \n",
    "    data['Credit_Num_Score'] = data[number].sum(axis=1)\n",
    "    data['Credit_Num_AVG_Score'] = data[number].mean(axis=1)\n",
    "    data['Credit_Num_Score'] = Standardize(data['Credit_Num_Score'])\n",
    "    data['Credit_Num_AVG_Score'] = Standardize(data['Credit_Num_AVG_Score'])\n",
    "    model_num = cluster.KMeans(n_clusters = 25)\n",
    "    data['Credit_Num_Score_clusters'] = model_num.fit_predict(data[['Credit_Num_Score', 'default_risk_std']])\n",
    "    \n",
    "    #Credit HH % Clustering Engineering\n",
    "    hh_percent = []\n",
    "    for columns in credit_hh_clusters: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 100, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        hh_percent.append(name)\n",
    "    pca = PCA(n_components = 7)\n",
    "    pc = pca.fit_transform(data[credit_bal_clusters])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_credithh', 'PCA2_credithh', 'PCA3_credithh', \n",
    "                                                  'PCA4_credithh', 'PCA5_credithh', 'PCA6_credithh',\n",
    "                                                  'PCA7_credithh'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    data['Credit_HH_Score'] = data[hh_percent].sum(axis=1)\n",
    "    data['Credit_HH_AVG_Score'] = data[hh_percent].mean(axis=1)\n",
    "    data['Credit_HH_Score'] = Standardize(data['Credit_HH_Score'])\n",
    "    data['Credit_HH_AVG_Score'] = Standardize(data['Credit_HH_AVG_Score'])\n",
    "    model_hh = cluster.KMeans(n_clusters = 25)\n",
    "    data['Credit_HH_Score_clusters'] = model_hh.fit_predict(data[['Credit_HH_Score', 'default_risk_std']])\n",
    "\n",
    "    credit = age_accounts + percent_balance + credit_bal_clusters +\\\n",
    "    credit_num_clusters + ['default_risk_std'] + credit_hh_clusters\n",
    "    \n",
    "    for column in credit:\n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FillNaN(data):\n",
    "    '''\n",
    "    Fills all NAN values based on certain criteria \n",
    "    \n",
    "    Takes one input:\n",
    "    data: a pandas dataframe\n",
    "    \n",
    "    Returns dataframe with all NAN values filled (which aren't tied to another function)\n",
    "    '''\n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMSEngineering(data): \n",
    "    '''\n",
    "    Creates new features based on CMS Risk Adjusted Information information\n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "\n",
    "    data['cms_risk_ma_nbr_rx_combined'] = data['cms_ma_risk_score_nbr'] * data['cms_rx_risk_score_nbr'] / 2 * (data['cms_ma_risk_score_nbr'] + data['cms_rx_risk_score_nbr'])\n",
    "    data['reverse_raf'] = data['cms_risk_adjustment_factor_a_amt'] / (1 + data['hcc_weighted_sum'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def healthFactorsEngineering(data): \n",
    "    '''\n",
    "    Creates new features based on some of the health scoring metrics\n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    cms_numeric_data = ['cms_partd_ra_factor_amt',\n",
    "                        'cms_risk_adj_payment_rate_a_amt',\n",
    "                        'cms_risk_adj_payment_rate_b_amt',\n",
    "                        'cms_risk_adjustment_factor_a_amt',\n",
    "                        'cms_tot_ma_payment_amt']\n",
    "    \n",
    "    data['life_remain'] = (67.98999 + data['sex_cd'] * 5 + (data['est_age'] * -0.67718)) * ((-6.51961 * data['cci_score'] + 104.04545) / 100)\n",
    "    \n",
    "    data['cci_score'] = (data['cci_score'] - data['cci_score'].min()) / (data['cci_score'].max() - data['cci_score'].min())\n",
    "    data['dcsi_score'] = (data['dcsi_score'] - data['dcsi_score'].min()) / (data['dcsi_score'].max() - data['dcsi_score'].min())\n",
    "    data['fci_score'] = (data['fci_score'] - data['fci_score'].min()) / (data['fci_score'].max() - data['fci_score'].min())\n",
    "    data['hcc_weighted_sum'] = (data['hcc_weighted_sum'] - data['hcc_weighted_sum'].min()) / (data['hcc_weighted_sum'].max() - data['hcc_weighted_sum'].min())\n",
    "\n",
    "    data['weighted_three_scores'] = data['fci_score'] * .40 + data['cci_score'] * .40  + data['dcsi_score'] * .20\n",
    "    data['weighted_full_health']= data['fci_score'] * .25 + data['cci_score'] * .25  + data['dcsi_score'] * .25 + data['hcc_weighted_sum'] * 0.25\n",
    "    \n",
    "    pca = PCA(n_components = 2)\n",
    "    pc = pca.fit_transform(data[cms_numeric_data])\n",
    "    \n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_cms', 'PCA2_cms'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    labels = range(1,101)\n",
    "    cms = []\n",
    "    for columns in cms_numeric_data: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 100, labels = labels)\n",
    "        cms.append(name)\n",
    "        data[name] = data[name].astype(int)\n",
    "    \n",
    "    data['CMS_Score'] = data[cms].sum(axis=1)\n",
    "    data['CMS_AVG_Score'] = data[cms].mean(axis=1)\n",
    "    data['CMS_Score'] = Standardize(data['CMS_Score'])\n",
    "    data['CMS_AVG_Score'] = Standardize(data['CMS_AVG_Score'])\n",
    "    data['weighted_full_health_std'] = Standardize(data['weighted_full_health'])\n",
    "\n",
    "    model_cms = cluster.KMeans(n_clusters = 20)\n",
    "    data['CMS_Score_clusters'] = model_cms.fit_predict(data[['CMS_Score', 'weighted_full_health_std']])\n",
    "    \n",
    "    cms_numeric_data += ['weighted_full_health_std']\n",
    "    \n",
    "    for cms_numeric in cms_numeric_data:\n",
    "        data.drop(cms_numeric, inplace = True, axis = 1)\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DummyVariables(data, skip): \n",
    "    '''\n",
    "    Creates dummy variable columns for all categorical data\n",
    "    \n",
    "    Takes two argument:\n",
    "    \n",
    "    data: A pandas dataframe (with categorical variables)\n",
    "    drop: boolean value whether dropfirst is true\n",
    "    \n",
    "    Returns a pandas data frame with \n",
    "    '''\n",
    "    if skip:\n",
    "        data = data.set_index('person_id_syn')\n",
    "    data = pd.get_dummies(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MobilityandStressIndex(data):\n",
    "    '''\n",
    "    Creates two new weighted index scores from the financial, health, and demogaphic data provided.\n",
    "    (Must be run after dummy variables are created)\n",
    "    \n",
    "    Takes one input: \n",
    "    data: a pandas data frame \n",
    "    \n",
    "    Returns a pandas dataframe with two new index scores\n",
    "    '''\n",
    "    \n",
    "    dummy_columns_to_drop  = ['cms_ra_factor_type_cd_Unknown','cons_cmys_Unknown',\n",
    "                             'cons_hhcomp_Unknown', 'cons_homstat_Unknown']\n",
    "    \n",
    "    \n",
    "    data['MobilityIndex'] = 0.2021 * data['cms_disabled_ind'] + 0.1295 * data['est_age'] / data['est_age'].max() +\\\n",
    "                        0.1062 * data['life_remain'] / data['life_remain'].max() + 0.0586 * data['credit_financial_index'] +\\\n",
    "                        0.0725 * data['cons_n65p_y'] + 0.0572 * data['cms_low_income_ind'] + 0.034 * data['cons_n2pmv'] +\\\n",
    "                        0.151 * data['weighted_full_health'] + data['hlth_pgm_slvrsnkr_par_status'] * -0.03 +\\\n",
    "                        0.1207 * (9 - data['rucc_category']) + 0.1364 * data['cons_hhcomp_Min Two People, Children'] +\\\n",
    "                        0.00521 * data['cons_hhcomp_Min Two People, No Children'] + 0.0682 * data['cons_hhcomp_One Person, Children']+\\\n",
    "                        0.02728 * data['cons_hhcomp_One Person, No Children'] + 0.0492 * data['cons_hhcomp_Unknown']\n",
    "    data['MobilityIndex'] = (data['MobilityIndex'] - data['MobilityIndex'].min()) /\\\n",
    "                            (data['MobilityIndex'].max() - data['MobilityIndex'].min())\n",
    "    \n",
    "    \n",
    "    data['StressIndex'] = 0.027 * data['cons_veteran_y'] + 0.1517 * data['credit_financial_index'] +\\\n",
    "                      0.0385 * data['cons_n65p_y'] + 0.1326 * data['cms_low_income_ind'] +\\\n",
    "                      0.2243 * data['default_risk'] + 0.0293 * data['smoker_current_ind'] +\\\n",
    "                      0.0783 * data['submcc_men_alco_ind'] + 0.0921 * data['submcc_men_depr_ind'] +\\\n",
    "                      0.0894 * data['submcc_men_abus_ind'] + 0.0868 * data['cons_hhcomp_Min Two People, Children'] +\\\n",
    "                      0.05872 * data['cons_hhcomp_Min Two People, No Children'] + 0.1468 * data['cons_hhcomp_One Person, Children']+\\\n",
    "                      0.02936 * data['cons_hhcomp_One Person, No Children'] + 0.08808 * data['cons_hhcomp_Unknown']\n",
    "    \n",
    "    \n",
    "    data['StressIndex'] = (data['StressIndex'] - data['StressIndex'].min()) /\\\n",
    "                            (data['StressIndex'].max() - data['StressIndex'].min())\n",
    "    data['est_age'] = np.log(data['est_age'])\n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    for dummy in dummy_columns_to_drop:\n",
    "        data.drop(dummy, inplace = True, axis = 1)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hospitalEngineering(data):\n",
    "    '''\n",
    "    Drops all the columns related to hospital visits that have 0 values\n",
    "    Add two columns: \n",
    "    \n",
    "    1. total_emer_visits\n",
    "    2. total_admit_days\n",
    "    \n",
    "    Drops all the admit days after summing them into the total_admit_days column\n",
    "    \n",
    "    One input: DataFrame\n",
    "    '''\n",
    "    data.drop(columns = ['total_ip_ltach_admit_ct_pmpm','total_ip_ltach_admit_days_pmpm','total_ip_maternity_admit_ct_pmpm'\n",
    "                         ,'total_ip_maternity_admit_days_pmpm'],inplace = True)\n",
    "\n",
    "    data['total_emer_visits'] = data['total_ambulance_visit_ct_pmpm'] + data['total_er_visit_ct_pmpm']\n",
    "\n",
    "    data['total_admit_days'] = data['total_ip_acute_admit_days_pmpm'] + data['total_ip_mhsa_admit_days_pmpm'] +\\\n",
    "                               data['total_ip_rehab_admit_days_pmpm'] + data['total_ip_snf_admit_days_pmpm']\n",
    "    \n",
    "    data.drop(['total_ip_acute_admit_days_pmpm','total_ip_mhsa_admit_days_pmpm','total_ip_rehab_admit_days_pmpm',\n",
    "              'total_ip_snf_admit_days_pmpm'], axis = 1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RxEngineering(data):\n",
    "    '''\n",
    "    Creates two new weighted index scores from the financial, health, and demogaphic data provided.\n",
    "    (Must be run after dummy variables are created)\n",
    "    \n",
    "    Takes one input: \n",
    "    data: a pandas data frame \n",
    "    \n",
    "    Returns a pandas dataframe with two new index scores\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    rx_columns = ((data.filter(like=\"rx\", axis=1).columns)&(data.filter(like=\"pmpm_ct\", axis=1).columns)).tolist()\n",
    "\n",
    "    pca = PCA(n_components = 5)\n",
    "    pc = pca.fit_transform(data[rx_columns])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_rx', 'PCA2_rx', 'PCA3_rx', \n",
    "                                                  'PCA4_rx', 'PCA5_rx'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    labels = range(1,101)\n",
    "    rx_list = []\n",
    "    for columns in rx_columns : \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 100, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        rx_list.append(name)\n",
    "    \n",
    "    data['RX_Score'] = data[rx_list].sum(axis=1)\n",
    "    data['RX_AVG_Score'] = data[rx_list].mean(axis=1)\n",
    "    data['RX_Score'] = Standardize(data['RX_Score'])\n",
    "    data['RX_AVG_Score'] = Standardize(data['RX_AVG_Score'])\n",
    "    model_rx = cluster.KMeans(n_clusters = 25)\n",
    "    data['RX_Score_clusters'] = model_rx.fit_predict(data[['RX_Score', 'est_age_std']])\n",
    "    \n",
    "    for rx in rx_columns:\n",
    "        data.drop(rx, inplace = True, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalize into a function \n",
    "def EngineerSUBMCC_PMPMcolumns(data):\n",
    "    \"\"\"\n",
    "    Groups the SUBMCC PMPM columns\n",
    "    \n",
    "    One Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "    \n",
    "    Returns pandas DataFrame with updated columns to replace for all submcc_pmpm_ct \n",
    "    \"\"\"\n",
    "\n",
    "    # drop _ano, _inf, _pre, _hiv, _trm; keep 23 mcc_pmpm columns\n",
    "    mcc_list = [ \"_ben\", \"_bld\", \"_brn\", \"_cad\", \"_can\", \"_cer\", \"_cir\", \"_dia\", \n",
    "                \"_dig\", \"_end\", \"_gus\", \"_hdz\", \"_inj\",\"_men\", \"_mus\", \"_ner\",\"_rar\", \"_res\", \"_rsk\", \"_skn\", \"_sns\", \"_sor\", \"_vco\"]\n",
    "\n",
    "    labels = range(1,101)\n",
    "    submcc_list = []\n",
    "    for mcc in mcc_list:\n",
    "        count = 'count' + mcc \n",
    "        data[count] = data[(data.filter(like=mcc, axis=1).columns) & (data.filter(like=\"pmpm_ct\", axis=1).columns)].sum(axis=1)\n",
    "        name = count + \"_rank\"\n",
    "        data[name] = pd.qcut(data[count].rank(method = 'first'), q = 100, labels = labels)\n",
    "        submcc_list.append(name)\n",
    "        data[name] = data[name].astype(int)\n",
    "        \n",
    "\n",
    "    columns = ((data.filter(like=\"submcc\", axis=1).columns)&(data.filter(like=\"pmpm_ct\", axis=1).columns)).tolist()\n",
    "    \n",
    "    pca = PCA(n_components = 30)\n",
    "    pc = pca.fit_transform(data[columns])\n",
    "    \n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_submcc', 'PCA2_submcc', 'PCA3_submcc', \n",
    "                                                  'PCA4_submcc', 'PCA5_submcc', 'PCA6_submcc',\n",
    "                                                  'PCA7_submcc', 'PCA8_submcc', 'PCA9_submcc',\n",
    "                                                  'PCA10_submcc', 'PCA11_submcc', 'PCA12_submcc', \n",
    "                                                  'PCA13_submcc', 'PCA14_submcc', 'PCA15_submcc', \n",
    "                                                  'PCA16_submcc', 'PCA17_submcc', 'PCA18_submcc',\n",
    "                                                  'PCA19_submcc', 'PCA20_submcc', 'PCA21_submcc',\n",
    "                                                  'PCA22_submcc', 'PCA23_submcc', 'PCA24_submcc', \n",
    "                                                  'PCA25_submcc', 'PCA26_submcc', 'PCA27_submcc', \n",
    "                                                  'PCA28_submcc', 'PCA29_submcc', 'PCA30_submcc'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    data['SUBMCC_Score'] = data[submcc_list].sum(axis=1)\n",
    "    data['SUBMCC_AVG_Score'] = data[submcc_list].mean(axis=1)\n",
    "    data['SUBMCC_Score'] = Standardize(data['SUBMCC_Score'])\n",
    "    data['SUBMCC_AVG_Score'] = Standardize(data['SUBMCC_AVG_Score'])\n",
    "    data['est_age_std'] = Standardize(data['est_age'])\n",
    "    model_submcc = cluster.KMeans(n_clusters = 30)\n",
    "    data['SUBMCC_Score_clusters'] = model_submcc.fit_predict(data[['SUBMCC_Score', 'est_age_std']])\n",
    "    \n",
    "    for column in columns: \n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeMaxMin(data, columnname):\n",
    "    \n",
    "    data[columnname] = (data[columnname] - data[columnname].min()) /\\\n",
    "    (data[columnname].max() - data[columnname].min())\n",
    "    \n",
    "    return data[columnname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Standardize(data):\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clustering(data):\n",
    "    data['MobilityIndex_std'] = Standardize(data['MobilityIndex'])\n",
    "    data['StressIndex_std'] = Standardize(data['StressIndex'])\n",
    "    data['default_risk_std'] = Standardize(data['default_risk'])\n",
    "    data['est_age_std'] = Standardize(data['est_age'])\n",
    "    data['credit_financial_index_std'] = Standardize(data['credit_financial_index'])\n",
    "    data['life_remain_std'] = Standardize(data['life_remain'])\n",
    "    data['reverse_raf_std'] = Standardize(data['reverse_raf'])\n",
    "    data['weighted_full_health_std'] = Standardize(data['weighted_full_health'])\n",
    "    \n",
    "    model20 = cluster.KMeans(n_clusters = 4)\n",
    "    model15 = cluster.KMeans(n_clusters = 3)\n",
    "    model10 = cluster.KMeans(n_clusters = 3)\n",
    "    data['Credit_All_clusters'] = model20.fit_predict(data[['Credit_Bal_Score', 'Credit_Num_Score', \n",
    "                                                              'Credit_HH_Score']])\n",
    "    data['Credit_All_AVG_clusters'] = model20.fit_predict(data[['Credit_Bal_AVG_Score', 'Credit_Num_AVG_Score', \n",
    "                                                              'Credit_HH_AVG_Score']])\n",
    "    data['Credit_Stress_clusters'] = model15.fit_predict(data[['Credit_Bal_Score', 'Credit_Num_Score', 'Credit_HH_Score', \n",
    "                                                             'est_age_std', 'StressIndex_std', 'life_remain_std', 'reverse_raf_std']])\n",
    "    data['Credit_RAFRisk_clusters'] = model15.fit_predict(data[['Credit_Bal_AVG_Score', 'Credit_Num_AVG_Score', 'Credit_HH_AVG_Score', \n",
    "                                                              'life_remain_std', 'reverse_raf_std']])\n",
    "    data['Credit_Composite_clusters'] = model15.fit_predict(data[['Credit_Bal_Score', 'Credit_Num_Score', 'Credit_HH_Score', \n",
    "                                                                'default_risk_std', 'credit_financial_index_std',\n",
    "                                                                'StressIndex_std']])\n",
    "    data['Mobile_Health_clusters'] = model15.fit_predict(data[['SUBMCC_Score', 'RX_Score', 'MobilityIndex_std', \n",
    "                                                             'weighted_full_health_std', 'CMS_Score']])\n",
    "    data['Health_Risk_clusters'] = model20.fit_predict(data[['weighted_full_health_std', 'life_remain_std', 'MobilityIndex_std', \n",
    "                                                          'est_age_std', 'reverse_raf_std']])\n",
    "    data['Credit_Health_Stress_clusters'] = model10.fit_predict(data[['Betos_Score','Credit_Bal_AVG_Score', 'Credit_Num_AVG_Score', 'Credit_HH_AVG_Score', \n",
    "                                                                    'StressIndex_std']])\n",
    "    data['General_Mobility_clusters'] = model10.fit_predict(data[['Betos_Score','est_age_std', 'CMS_Score', \n",
    "                                                                'MobilityIndex_std']])\n",
    "    data['Health_Credit_Assesment_clusters'] = model10.fit_predict(data[['Betos_Score','Credit_Bal_AVG_Score', 'Credit_Num_AVG_Score', \n",
    "                                                                       'est_age_std', 'weighted_full_health_std', 'Credit_HH_AVG_Score',\n",
    "                                                                        'MobilityIndex_std']])\n",
    "    data['General_Health_clusters'] = model15.fit_predict(data[['life_remain_std', 'est_age_std', 'weighted_full_health_std']])\n",
    "    data['General_HealthMobile_clusters'] = model15.fit_predict(data[['life_remain_std', 'MobilityIndex_std',\n",
    "                                                                    'est_age_std', 'weighted_full_health_std']])\n",
    "    data['Health_Scores_clusters'] = model15.fit_predict(data[['SUBMCC_Score', 'Betos_Score',\n",
    "                                                             'CMS_Score', 'RX_Score', 'MobilityIndex_std']])\n",
    "    data['Full_Credit_clusters'] = model15.fit_predict(data[['Credit_Bal_Score', 'Credit_Num_Score', 'Credit_HH_Score', \n",
    "                                                           'credit_financial_index_std', 'default_risk_std', 'est_age_std']])\n",
    "    data['Full_AVG_Credit_clusters'] = model15.fit_predict(data[['Credit_Bal_AVG_Score', 'Credit_Num_AVG_Score', 'Credit_HH_AVG_Score', \n",
    "                                'credit_financial_index_std', 'default_risk_std', 'est_age_std']])\n",
    "    \n",
    "    to_drop = ['MobilityIndex_std', 'StressIndex_std', 'default_risk_std', 'est_age_std', \n",
    "               'credit_financial_index_std', 'life_remain_std', 'reverse_raf_std', \n",
    "               'weighted_full_health_std']\n",
    "    \n",
    "    for droped in to_drop: \n",
    "        data.drop(droped, inplace = True, axis = 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped:  hedis_ami\n",
      "Dropped:  hedis_cmc_ldc_c_control\n",
      "Dropped:  hedis_cmc_ldc_c_screen\n"
     ]
    }
   ],
   "source": [
    "health = mapStringVariables(health)\n",
    "health = dropMajorityNAcolumns(health)\n",
    "health = FillNaN(health)\n",
    "health = columnBinning(health)\n",
    "health = columnsToDrop(health)\n",
    "health = LabelEncoding(health)\n",
    "health = betosEngineering(health)\n",
    "health = medEngineering(health)\n",
    "health = creditDataEngineering(health)\n",
    "health = CMSEngineering(health)\n",
    "health = healthFactorsEngineering(health)\n",
    "health = hospitalEngineering(health)\n",
    "health = EngineerSUBMCC_PMPMcolumns(health)\n",
    "health = RxEngineering(health)\n",
    "health = DummyVariables(health, True)\n",
    "health = MobilityandStressIndex(health)\n",
    "health = Clustering(health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "#health = health.drop('transportation_issues', axis = 1)\n",
    "model = IsolationForest(n_jobs = -1, n_estimators = 1000, max_features = 765)\n",
    "model.fit(health)\n",
    "health['anomaly_decision'] = model.predict(health)\n",
    "health['anomaly_score'] = model.decision_function(health.drop('anomaly_decision', axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "health['betos_m5c_pmpm_ct + betos_o1g_pmpm_ct'] = original['betos_m5c_pmpm_ct'] + original['betos_o1g_pmpm_ct']\n",
    "health['betos_o1a_pmpm_ct * cons_n2pmv'] = original['betos_o1a_pmpm_ct'] * original['cons_n2pmv']\n",
    "health['total_ambulance_visit_ct_pmpm + total_er_visit_ct_pmpm'] = original['total_ambulance_visit_ct_pmpm'] + original['total_er_visit_ct_pmpm']\n",
    "health['cms_partd_ra_factor_amt * cms_tot_partd_payment_amt'] = original['cms_partd_ra_factor_amt'] * original['cms_tot_partd_payment_amt']\n",
    "health['cms_ma_risk_score_nbr + cms_tot_partd_payment_amt'] = original['cms_ma_risk_score_nbr'] + original['cms_tot_partd_payment_amt']\n",
    "health['credit_hh_autofinance * credit_num_totalallcredit_collections'] = original['credit_hh_autofinance'] * original['credit_num_totalallcredit_collections']\n",
    "health['credit_hh_bankcard_severederog + credit_num_autobank'] = original['credit_hh_bankcard_severederog'] + original['credit_num_autobank']\n",
    "health['cms_tot_ma_payment_amt * cons_n2pmv'] = original['cms_tot_ma_payment_amt'] * original['cons_n2pmv']\n",
    "health['credit_bal_consumerfinance_new * credit_hh_autobank_new'] = original['credit_bal_consumerfinance_new'] * original['credit_hh_autobank_new']\n",
    "health['fci_score + weighted_full_health'] = health['fci_score'] + health['weighted_full_health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "health['rx_overall_pmpm_ct'] = original['rx_overall_pmpm_ct']\n",
    "health['rx_mail_pmpm_ct'] =original['rx_mail_pmpm_ct']\n",
    "health['submcc_men_depr_pmpm_ct']=original['submcc_men_depr_pmpm_ct']\n",
    "health['rx_gpi2_17_pmpm_ct']=original['rx_gpi2_17_pmpm_ct']\n",
    "health['submcc_ben_othr_pmpm_ct']=original['submcc_ben_othr_pmpm_ct']\n",
    "health['rx_gpi2_39_pmpm_ct']=original['rx_gpi2_39_pmpm_ct']\n",
    "health['submcc_sor_eye_pmpm_ct']=original['submcc_sor_eye_pmpm_ct']\n",
    "health['rx_branded_pmpm_ct']=original['rx_branded_pmpm_ct']\n",
    "health['submcc_men_abus_pmpm_ct']=original['submcc_men_abus_pmpm_ct']\n",
    "health['rx_gpi2_43_pmpm_ct']=original['rx_gpi2_43_pmpm_ct']\n",
    "health['rx_gpi2_49_pmpm_ct']=original['rx_gpi2_49_pmpm_ct']\n",
    "health['submcc_vco_vac_pmpm_ct']=original['submcc_vco_vac_pmpm_ct']\n",
    "health['rx_gpi2_75_pmpm_ct']=original['rx_gpi2_75_pmpm_ct']\n",
    "health['submcc_rsk_smok_pmpm_ct']=original['submcc_rsk_smok_pmpm_ct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_features = ['Credit_Stress_clusters','cms_risk_ma_nbr_rx_combined','med_ambulance_visit_ct_pmpm',\n",
    "'est_age','cms_low_income_ind','cons_n2pmv','count_vco','cms_disabled_ind','submcc_ner_othr_ind',\n",
    "'credit_hh_dpd_average', 'cms_risk_adjustment_factor_a_amt_rank','betos_o1a_ind','StressIndex',\n",
    "'credit_num_totalallcredit_collections','submcc_ben_othr_ind','betos_m5d_pmpm_ct_rank','cons_n2mob',\n",
    "'PCA18_submcc','betos_y2_ind','betos_m5b_pmpm_ct_rank', 'reverse_raf', 'hedis_dia_hba1c_test', 'count_bld_rank',\n",
    "'cons_homstat_Renter', 'anomaly_score', 'mabh_seg_H2', 'betos_m5c_pmpm_ct + betos_o1g_pmpm_ct', \n",
    "'total_physician_office_visit_ct_pmpm', 'rx_gpi2_90_pmpm_ct_rank', 'PCA4_creditbal', 'count_mus',\n",
    "'rx_gpi2_17_pmpm_ct_rank', 'betos_o1a_pmpm_ct * cons_n2pmv', 'total_ambulance_visit_ct_pmpm + total_er_visit_ct_pmpm',\n",
    "'cms_partd_ra_factor_amt * cms_tot_partd_payment_amt', 'total_ambulance_visit_ct_pmpm', 'weighted_full_health',\n",
    "'med_physician_office_visit_ct_pmpm', 'cons_retail_buyer', 'cons_hhcomp_Min Two People, No Children',\n",
    "'count_ner_rank', 'total_emer_visits', 'credit_hh_nonmtgcredit_60dpd_rank', 'count_can', 'PCA3_rx', \n",
    "'cons_hhcomp_One Person, Children', 'med_outpatient_visit_ct_pmpm', 'cms_ma_risk_score_nbr + cms_tot_partd_payment_amt',\n",
    "'fci_score', 'cci_score', 'hcc_weighted_sum','rx_overall_pmpm_ct','rx_mail_pmpm_ct','submcc_men_depr_pmpm_ct',\n",
    "'rx_gpi2_17_pmpm_ct','submcc_ben_othr_pmpm_ct','rx_gpi2_39_pmpm_ct','submcc_sor_eye_pmpm_ct',\n",
    "'rx_branded_pmpm_ct','submcc_men_abus_pmpm_ct','rx_gpi2_43_pmpm_ct','rx_gpi2_49_pmpm_ct',\n",
    "'submcc_vco_vac_pmpm_ct','rx_gpi2_75_pmpm_ct','submcc_rsk_smok_pmpm_ct', 'credit_hh_totalallcredit_severederog_rank',\n",
    "'ccsp_239_ind', 'anomaly_decision','credit_hh_autofinance * credit_num_totalallcredit_collections',\n",
    "'credit_hh_bankcard_severederog + credit_num_autobank','cms_tot_ma_payment_amt * cons_n2pmv',\n",
    "'credit_bal_consumerfinance_new * credit_hh_autobank_new', 'fci_score + weighted_full_health']\n",
    "\n",
    "health = health[health_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "health.fillna(0, inplace = True, axis = 1)\n",
    "#health['transportation_issues'] = original['transportation_issues']\n",
    "health.to_csv('data/HOLDOUT_FINAL.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
