{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tvAR1r5FdT4P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import cluster\n",
    "from sklearn.decomposition import PCA\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.display.max_rows = 999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e4Ms3BDWdT4T",
    "outputId": "ef3190ca-0593-40eb-e30a-c12bd09f83ae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kpainton/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (80,193) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "original = pd.read_csv(\"data/2020_Competition_Training.csv\")\n",
    "health = original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mRo4Mbr0dT4Z"
   },
   "outputs": [],
   "source": [
    "def mapStringVariables(data):\n",
    "    \"\"\"\n",
    "    Reorganizes columns to alphabetical order, Maps all string variables into new groups.  Prepares string values\n",
    "    to be turned into dummy variables. \n",
    "    \n",
    "    One input:\n",
    "    \n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns pandas data frame Variables remapped to prepare to create dummy variables \n",
    "    \"\"\"\n",
    "    data = data.reindex(sorted(data.columns), axis = 1)\n",
    "    data['cons_cmys'] = data['cons_cmys'].map({'0':'Unknown',\n",
    "                                                          '1': 'Less Than High School',\n",
    "                                                          '2': 'Less Than High School', \n",
    "                                                          '3': 'High School Diploma',\n",
    "                                                          '4': 'Some College', \n",
    "                                                          '5': 'Associate Degree',\n",
    "                                                          '6': 'Bachelors Degree',\n",
    "                                                          '7': 'Graduate Degree', \n",
    "                                                          '8': 'Professional School Degree',\n",
    "                                                          '9': 'Doctorate Degree'})\n",
    "    data['cons_cmys'].fillna('Unknown', inplace = True)\n",
    "    data['cons_hhcomp'] = data['cons_hhcomp'].map({'A':'Min Two People, Children',\n",
    "                                                          'C': 'Min Two People, Children',\n",
    "                                                          'D': 'Min Two People, No Children', \n",
    "                                                          'E': 'Min Two People, Children',\n",
    "                                                          'F': 'Min Two People, No Children', \n",
    "                                                          'G': 'Min Two People, Children',\n",
    "                                                          'H': 'Min Two People, No Children',\n",
    "                                                          'B': 'Min Two People, No Children', \n",
    "                                                          'I': 'One Person, Children',\n",
    "                                                          'J': 'One Person, No Children',\n",
    "                                                          'K': 'One Person, Children', \n",
    "                                                          'L': 'One Person, No Children',\n",
    "                                                          'U': 'Unknown'})\n",
    "    data['cons_hhcomp'].fillna('Unknown', inplace = True)\n",
    "    data['cms_ra_factor_type_cd'] = data['cms_ra_factor_type_cd'].map({'CN': 'CN',\n",
    "                                                                      'CP': 'CP',\n",
    "                                                                      'E': 'E',\n",
    "                                                                      'CF': 'CF',\n",
    "                                                                      'D':'D',\n",
    "                                                                      '1': 'Other',\n",
    "                                                                      'C2' : 'Other',\n",
    "                                                                      'I': 'Other',\n",
    "                                                                      'SE': 'Other',\n",
    "                                                                      '*': 'Other'})\n",
    "\n",
    "    data['cms_ra_factor_type_cd'].fillna('Unknown', inplace = True)\n",
    "    data['cons_homstat'] = data['cons_homstat'].map({'P': 'Homeowner',\n",
    "                                                                 'R': 'Renter',\n",
    "                                                                 'T': 'Renter',\n",
    "                                                                 'U': 'Unknown',\n",
    "                                                                 'Y': 'Homeowner'})\n",
    "    data['cons_homstat'].fillna('Unknown', inplace = True)\n",
    "    \n",
    "    data['sex_cd'] = data['sex_cd'].map({'M': 0, 'F': 1})\n",
    "    for i in range(203, 212):\n",
    "        data.iloc[:,i] = data.iloc[:,i].map({'Y': 1, 'N': 0})\n",
    "        \n",
    "    data['lang_spoken_cd'] = data['lang_spoken_cd'].map({'E': 'ENG', 'ENG': 'ENG', 'SPA': 'SPA'})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9JFcckuJdT4d"
   },
   "outputs": [],
   "source": [
    "def dropMajorityNAcolumns(data, threshold = 0.5):\n",
    "    \"\"\"\n",
    "    Drops all columns from data that have a certain NA percentage of values above the threshold. \n",
    "    \n",
    "    Two Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "    threshold (default = 0.5): a non-negative value (from 0.0 to 1.0) that represents a threshold percentage for \n",
    "    which columns to drop\n",
    "    \n",
    "    Returns pandas DataFrame with dropped columns\n",
    "    \"\"\"\n",
    "    \n",
    "    for column in data.columns:\n",
    "        if (data[column].isna().sum() / len(data[column])) >= threshold:\n",
    "            data.drop(column, inplace = True, axis = 1)\n",
    "            print(\"Dropped: \", column)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RJCuLvRdT4j"
   },
   "outputs": [],
   "source": [
    "def columnBinning(data):\n",
    "    \"\"\"\n",
    "    Groups columns into specific bins, removes their original columns\n",
    "    \n",
    "    One Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "\n",
    "    Returns pandas DataFrame with new columns, removes columns that are not of interest\n",
    "    \"\"\"\n",
    "    \n",
    "    ccsp_columns = ['ccsp_014_ind', 'ccsp_021_ind', 'ccsp_034_ind', 'ccsp_060_ind', 'ccsp_080_ind', 'ccsp_107_ind',\n",
    "                   'ccsp_125_ind', 'ccsp_204_ind', 'ccsp_212_ind', 'ccsp_242_ind']\n",
    "    \n",
    "    data['cons_n2mob'] = round(data['cons_n2mob'], 2) / 100\n",
    "    data['cons_n2pbl'] = round(data['cons_n2pbl'], 2) / 100\n",
    "    data['cons_n2pmv'] = round(data['cons_n2pmv'], 2) / 100\n",
    "    \n",
    "    \n",
    "    for ccsp_column in ccsp_columns: \n",
    "            data.loc[data[ccsp_column] == 1, 'ccsp_extra_group'] = 1\n",
    "            data.drop(ccsp_column, inplace = True, axis = 1)\n",
    "    data['ccsp_extra_group'].fillna(0, inplace = True)\n",
    "            \n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOLUHQAfdT4o"
   },
   "outputs": [],
   "source": [
    "def columnsToDrop(data): \n",
    "    \"\"\"\n",
    "    Drops all columns that are not going to be used in the model.  \n",
    "    \n",
    "    One Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "\n",
    "    Returns pandas DataFrame with dropped columns\n",
    "    \"\"\"\n",
    "    \n",
    "    columns_drop = ['lab_bnp_abn_result_ind', 'lab_hba1_c_abn_result_ind', 'med_ip_ltach_admit_ct_pmpm',\n",
    "                   'med_ip_ltach_admit_days_pmpm', 'med_ip_maternity_admit_ct_pmpm', 'med_ip_maternity_admit_days_pmpm',\n",
    "                   'med_ip_mhsa_admit_ct_pmpm', 'med_ip_mhsa_admit_days_pmpm',\n",
    "                    'src_platform_cd']\n",
    "    \n",
    "    columns_drop += [\"submcc_ano_mus_pmpm_ct\", \"submcc_ano_othr_pmpm_ct\",\"submcc_ben_lymp_pmpm_ct\",\"submcc_ben_ner_pmpm_ct\", \n",
    "                      \"submcc_brn_acc_pmpm_ct\",\"submcc_cad_fh/ho_pmpm_ct\",\"submcc_cad_ptca_pmpm_ct\", \"submcc_can_brst_pmpm_ct\",\n",
    "                     \"submcc_can_leuk_pmpm_ct\",\"submcc_can_ner_pmpm_ct\",\n",
    "                     \"submcc_gus_othr_pmpm_ct\",\"submcc_hdz_arrh_pmpm_ct\",\"submcc_hdz_it_i_pmpm_ct\",\"submcc_hdz_surg_pmpm_ct\",\n",
    "                      \"submcc_hdz_valv_pmpm_ct\",\"submcc_hiv_kapo_pmpm_ct\",\"submcc_hiv_pcp_pmpm_ct\",\"submcc_inf_men_pmpm_ct\",\n",
    "                      \"submcc_inf_myco_pmpm_ct\",\"submcc_inj_comp_pmpm_ct\",\"submcc_mus_othr_pmpm_ct\",\"submcc_neo_fh/ho_pmpm_ct\",\n",
    "                    \"submcc_pre_care_pmpm_ct\", \"submcc_pre_del_pmpm_ct\",\"submcc_pre_l/d_pmpm_ct\",\"submcc_pre_mul_pmpm_ct\",\n",
    "                    \"submcc_pre_ect_pmpm_ct\",\"submcc_pre_othr_pmpm_ct\",\"submcc_rar_als_pmpm_ct\",\n",
    "                    \"submcc_rar_cf_pmpm_ct\",\"submcc_rar_drm_pmpm_ct\",\"submcc_rar_mg_pmpm_ct\",\"submcc_rar_othr_pmpm_ct\",\n",
    "                    \"submcc_rar_pol_pmpm_ct\",\"submcc_rar_sca_pmpm_ct\",\"submcc_rar_scl_pmpm_ct\",\"submcc_rsk_an_pmpm_ct\",\n",
    "                    \"submcc_rsk_fh/h_pmpm_ct\",\"submcc_rsk_othr_pmpm_ct\",\"submcc_rsk_pcos_pmpm_ct\",\n",
    "                      \"submcc_trm_fxu_pmpm_ct\",\"submcc_trm_fxul_pmpm_ct\",\"submcc_vco_end_pmpm_ct\"]\n",
    "    \n",
    "    columns_drop += [\"submcc_ano_mus_ind\", \"submcc_ano_othr_ind\",\"submcc_ben_lymp_ind\",\"submcc_ben_ner_ind\", \n",
    "                      \"submcc_brn_acc_ind\",\"submcc_cad_fh/ho_ind\",\"submcc_cad_ptca_ind\", \"submcc_can_brst_ind\",\n",
    "                     \"submcc_can_leuk_ind\",\"submcc_can_ner_ind\",\n",
    "                     \"submcc_gus_othr_ind\",\"submcc_hdz_arrh_ind\",\"submcc_hdz_it_i_ind\",\"submcc_hdz_surg_ind\",\n",
    "                      \"submcc_hdz_valv_ind\",\"submcc_hiv_kapo_ind\",\"submcc_hiv_pcp_ind\",\"submcc_inf_men_ind\",\n",
    "                      \"submcc_inf_myco_ind\",\"submcc_inj_comp_ind\",\"submcc_mus_othr_ind\",\"submcc_neo_fh/ho_ind\",\n",
    "                    \"submcc_pre_care_ind\", \"submcc_pre_del_ind\",\"submcc_pre_l/d_ind\",\"submcc_pre_mul_ind\",\n",
    "                    \"submcc_pre_ect_ind\",\"submcc_pre_othr_ind\",\"submcc_rar_als_ind\",\n",
    "                    \"submcc_rar_cf_ind\",\"submcc_rar_drm_ind\",\"submcc_rar_mg_ind\",\"submcc_rar_othr_ind\",\n",
    "                    \"submcc_rar_pol_ind\",\"submcc_rar_sca_ind\",\"submcc_rar_scl_ind\",\"submcc_rsk_an_ind\",\n",
    "                    \"submcc_rsk_fh/h_ind\",\"submcc_rsk_othr_ind\",\"submcc_rsk_pcos_ind\",\n",
    "                      \"submcc_trm_fxu_ind\",\"submcc_trm_fxul_ind\",\"submcc_vco_end_ind\"]\n",
    "    \n",
    "    #columns_drop += ['rx_gpi2_07_ind','submcc_rar_ms_ind','submcc_end_othr_ind','submcc_rar_hem_ind','submcc_sns_coma_ind',\n",
    "    #                 'rx_gpi2_15_ind','submcc_brn_othr_ind','rx_gpi2_09_ind','submcc_sns_dth_ind','submcc_pre_com_ind','total_ip_rehab_admit_ct_pmpm',\n",
    "    #                 'rx_gpi2_48_ind','submcc_ner_infl_ind','med_ip_rehab_admit_ct_pmpm','rx_gpi2_51_ind','submcc_ano_cns_ind','submcc_trm_spnj_ind',\n",
    "    #                 'rev_cms_nicu_ind','rx_gpi2_92_ind','rx_gpi2_95_ind','rx_gpi2_96_ind','rx_gpi2_08_ind','rx_gpi2_69_ind','hlth_pgm_slvrsnkr_refer_status',\n",
    "    #                 'rx_gpi2_78_ind','rx_gpi2_70_ind','rx_gpi2_45_ind','rx_gpi2_74_ind','rx_gpi2_76_ind','ccsp_120_ind',\n",
    "    #                 'rx_gpi2_29_ind','rx_gpi2_80_ind','rx_gpi2_14_ind','rx_gpi2_81_ind','rx_gpi2_84_ind','rx_gpi2_20_pmpm_ct',\n",
    "    #                 'rx_gpi2_20_ind','rx_gpi2_19_ind','rx_gpi2_14_pmpm_ct', 'rx_gpi2_98_ind', 'rx_gpi2_23_ind',\n",
    "    #                 'rx_gpi2_25_ind','submcc_rar_par_ind','submcc_trm_brn_ind','submcc_inf_sep_ind','submcc_rsk_synx_ind','submcc_hdz_it_is_ind',\n",
    "    #                 'submcc_ben_unk_ind','submcc_hiv_othr_ind','submcc_trm_prly_ind','submcc_trm_skul_ind','submcc_rsk_coag_ind',\n",
    "    #                 'submcc_ano_gu_ind','submcc_mus_inf_ind','submcc_trm_hip_ind','submcc_can_end_ind','submcc_ano_dig_ind']\n",
    "    \n",
    "    #columns_drop += ['pdc_ast', 'pdc_cvd', 'pdc_dep', 'pdc_dia', 'pdc_hf', 'pdc_ht', 'pdc_lip', 'pdc_ost']\n",
    "                     \n",
    "    #columns_drop += ['hedis_dia_eye', 'hedis_dia_hba1c_ge9', 'hedis_dia_hba1c_test', 'hedis_dia_ldc_c_control',\n",
    "     #                'hedis_dia_ldc_c_screen', 'hedis_dia_ma_nephr', 'lab_abn_result_ind', \n",
    "     #                'lab_bun_abn_result_ind', 'lab_cholesterol_abn_result_ind','lab_creatinine_abn_result_ind','lab_egfr_abn_result_ind',\n",
    "      #               'lab_hemoglobin_abn_result_ind']\n",
    "    \n",
    "    for columns in columns_drop:\n",
    "        data.drop(columns, inplace = True, axis = 1)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8lPfS1WdT4r"
   },
   "outputs": [],
   "source": [
    "def LabelEncoding(data): \n",
    "    '''\n",
    "    Encodes Categorical data to levels to prepare for machine learning model \n",
    "    \n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    \n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    lb_make = LabelEncoder()\n",
    "    data['rucc_category'] = lb_make.fit_transform(data['rucc_category'])\n",
    "    data['state_cd'] = lb_make.fit_transform(data['rucc_category'])\n",
    "    data['mabh_seg'] = lb_make.fit_transform(data['mabh_seg'])\n",
    "    data['zip_cd'] = lb_make.fit_transform(data['zip_cd'])\n",
    "    data['cnty_cd'] = lb_make.fit_transform(data['cnty_cd'])\n",
    "    \n",
    "    pdc = ['pdc_ast', 'pdc_cvd', 'pdc_dep', 'pdc_dia', 'pdc_hf', 'pdc_ht', 'pdc_lip', 'pdc_ost']\n",
    "    for p in pdc: \n",
    "        data.loc[data[p] == 1.1, p] = 0\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Msuty6QndT4w"
   },
   "outputs": [],
   "source": [
    "def betosEngineering(data):\n",
    "    '''\n",
    "    Creates new features for three different groups in Betos: common, uncommon, and critical.  Sums all the claims\n",
    "    based on these three groups and returns the new columns. Afterwards, drops the old betos columns (pmpm_ct)\n",
    "    \n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    common_visits = ['betos_m1b_pmpm_ct', 'betos_o1b_pmpm_ct', 'betos_o1e_pmpm_ct', 'betos_o1g_pmpm_ct',\n",
    "                'betos_t1a_pmpm_ct', 'betos_t1b_pmpm_ct', 'betos_t1e_pmpm_ct', 'betos_t1h_pmpm_ct',\n",
    "                'betos_t2a_pmpm_ct', 'betos_y2_pmpm_ct']\n",
    "    uncommon = ['betos_d1c_pmpm_ct', 'betos_m5b_pmpm_ct', 'betos_m5c_pmpm_ct', 'betos_m5d_pmpm_ct']\n",
    "    critical = ['betos_d1d_pmpm_ct', 'betos_m2c_pmpm_ct', 'betos_o1a_pmpm_ct']\n",
    "\n",
    "    data['betos_common_visits_pmpm_ct'] = data[common_visits].sum(axis = 1)\n",
    "    data['betos_uncommon_visits_pmpm_ct'] = data[uncommon].sum(axis = 1)\n",
    "    data['betos_critical_visits_pmpm_ct'] = data[critical].sum(axis = 1)\n",
    "    \n",
    "    total = common_visits + uncommon + critical\n",
    "    \n",
    "    pca = PCA(n_components = 7)\n",
    "    pc = pca.fit_transform(data[total])\n",
    "    \n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_betos', 'PCA2_betos', 'PCA3_betos', \n",
    "                                                  'PCA4_betos', 'PCA5_betos', 'PCA6_betos',\n",
    "                                                  'PCA7_betos'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    labels = range(1,51)\n",
    "    betos_list = []\n",
    "    for single in total: \n",
    "        name = single + \"_rank\"\n",
    "        data[name] = pd.qcut(data[single].rank(method = 'first'), q = 50, labels = labels)\n",
    "        betos_list.append(name)\n",
    "        data[name] = data[name].astype(int)\n",
    "    \n",
    "    data['Betos_Score'] = data[betos_list].sum(axis=1)\n",
    "    data['Betos_AVG_Score'] = Standardize(data['Betos_Score'])\n",
    "    data['Betos_Score'] = data[betos_list].mean(axis=1)\n",
    "    data['Betos_AVG_Score'] = Standardize(data['Betos_Score'])\n",
    "    data['est_age_std'] = Standardize(data['est_age'])\n",
    "\n",
    "    model_betos = cluster.KMeans(n_clusters = 20)\n",
    "    data['Betos_Score_clusters'] = model_betos.fit_predict(data[['Betos_Score', 'est_age_std']])\n",
    "\n",
    "    for column in total:\n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlvHJAQWdT4z"
   },
   "outputs": [],
   "source": [
    "def medEngineering(data):\n",
    "    '''\n",
    "    Creates new feature based on total admitted days for non-BH related claims. \n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    med_admit = ['med_ip_acute_admit_days_pmpm', 'med_ip_rehab_admit_days_pmpm', 'med_ip_snf_admit_days_pmpm']\n",
    "    \n",
    "    data['med_admit_days'] = data[med_admit].sum(axis = 1)\n",
    "    for column in med_admit:\n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50Ke20OPdT41"
   },
   "outputs": [],
   "source": [
    "def creditDataEngineering(data): \n",
    "    '''\n",
    "    Creates new features based on credit data information\n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    from sklearn import cluster\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    credit_bal_general = ['credit_bal_autobank', 'credit_bal_autofinance', 'credit_bal_consumerfinance']\n",
    "    \n",
    "    credit_bal_new = ['credit_bal_agencyfirstmtg_new', 'credit_bal_autobank_new', 'credit_bal_autofinance_new',\n",
    "                     'credit_bal_consumerfinance_new','credit_bal_mtgcredit_new']\n",
    "    \n",
    "    credit_bal_dpd = ['credit_bal_1stmtg_30to59dpd', 'credit_bal_1stmtg_60to89dpd', 'credit_bal_1stmtgcredit_60dpd',\n",
    "                     'credit_bal_agencyfirstmtg_60dpd', 'credit_bal_heloc_60dpd', 'credit_bal_mtg_90to119dpd',\n",
    "                     'credit_bal_nonagn1stmorg_30to59dpd', 'credit_bal_nonagn1stmorg_60to89dpd', \n",
    "                     'credit_bal_nonagn1stmorg_90to119dp', 'credit_bal_nonagnfirstmtg_60dpd', 'credit_bal_nonmtgcredit_60dpd',\n",
    "                     'credit_bal_studentloan_60dpd']\n",
    "    \n",
    "    credit_bal_overage = ['credit_bal_1stmtg_collections', 'credit_bal_1stmtg_severederog', 'credit_bal_agency1stmorg_collectio',\n",
    "                         'credit_bal_bankcard_severederog', 'credit_bal_heloc_severederog', 'credit_bal_mtg_bankruptcy',\n",
    "                         'credit_bal_mtg_severederog', 'credit_bal_nonagn1stmorg_bankruptc', 'credit_bal_nonagn1stmorg_collectio']\n",
    "\n",
    "    credit_num_new = ['credit_num_1stmtgcredit_new', 'credit_num_agencyfirstmtg_new', 'credit_num_autobank_new',\n",
    "                 'credit_num_autofinance_new', 'credit_num_consumerfinance_new', 'credit_num_mtgcredit_new']\n",
    "\n",
    "    credit_num_general = ['credit_num_1stmtgcredit', 'credit_num_agencyfirstmtg', 'credit_num_autobank', \n",
    "                         'credit_num_autofinance', 'credit_num_consumerfinance', 'credit_num_studentloan']\n",
    "\n",
    "    credit_num_dpd = ['credit_num_1stmtg_30to59dpd', 'credit_num_1stmtg_60to89dpd', 'credit_num_agencyfirstmtg_60dpd',\n",
    "                      'credit_num_mtg_60to89dpd', 'credit_num_mtg_90to119dpd', 'credit_num_nonagn1stmorg_30to59dpd', \n",
    "                      'credit_num_nonagn1stmorg_60to89dpd', 'credit_num_nonagn1stmorg_90to119dp',\n",
    "                      'credit_num_nonmtgcredit_60dpd', 'credit_num_studentloan_60dpd', 'credit_num_heloc_60dpd']\n",
    "\n",
    "    credit_num_danger = ['credit_num_1stmtg_bankruptcy', 'credit_num_1stmtg_collections', 'credit_num_1stmtg_severederog',\n",
    "                         'credit_num_agency1stmorg_collectio', 'credit_num_bankcard_severederog', 'credit_num_heloc_severederog',\n",
    "                         'credit_num_mtg_collections', 'credit_num_mtg_severederog', 'credit_num_nonagn1stmorg_bankruptc',\n",
    "                         'credit_num_nonagn1stmorg_collectio']\n",
    "    \n",
    "    credit_hh_new = ['credit_hh_1stmtgcredit_new', 'credit_hh_agencyfirstmtg_new', 'credit_hh_autobank_new',\n",
    "                 'credit_hh_autofinance_new', 'credit_hh_consumerfinance_new', 'credit_hh_mtgcredit_new']\n",
    "\n",
    "    credit_hh_dpd = ['credit_hh_bankcardcredit_60dpd', 'credit_hh_nonmtgcredit_60dpd',\n",
    "                     'credit_hh_studentloan_60dpd']\n",
    "    \n",
    "    percent_balance = ['credit_prcnt_agencyfirstmtg', 'credit_prcnt_autobank',\n",
    "                      'credit_prcnt_mtgcredit', 'credit_prcnt_nonagnfirstmtg']\n",
    "    \n",
    "    credit_hh_clusters = ['credit_hh_1stmtg_severederog', 'credit_hh_1stmtgcredit', 'credit_hh_1stmtgcredit_new',\n",
    "                          'credit_hh_agencyfirstmtg', 'credit_hh_agencyfirstmtg_new', 'credit_hh_autobank',\n",
    "                          'credit_hh_autobank_new', 'credit_hh_autofinance', 'credit_hh_autofinance_new',\n",
    "                          'credit_hh_bankcard_severederog', 'credit_hh_bankcardcredit_60dpd',\n",
    "                          'credit_hh_consumerfinance', 'credit_hh_consumerfinance_new', 'credit_hh_mtg_severederog',\n",
    "                          'credit_hh_mtgcredit_new', 'credit_hh_nonagnfirstmtg', 'credit_hh_nonmtgcredit_60dpd',\n",
    "                          'credit_hh_studentloan', 'credit_hh_studentloan_60dpd', 'credit_hh_totalallcredit_bankruptcy',\n",
    "                          'credit_hh_totalallcredit_collections', 'credit_hh_totalallcredit_severederog']\n",
    "    \n",
    "    age_accounts = ['credit_minmob_1stmtgcredit', 'credit_minmob_agencyfirstmtg', 'credit_minmob_mtgcredit']\n",
    "    \n",
    "    credit_balance = ['credit_bal_totalallcredit_60dpd', 'credit_bal_totalallcredit_60to89dpd', 'credit_bal_totalallcredit_90to119dpd'\n",
    "                      'credit_bal_totalallcredit_new']\n",
    "    \n",
    "    credit_bal_clusters = credit_bal_general + credit_bal_dpd + credit_bal_overage + credit_bal_new\n",
    "    credit_num_clusters = credit_num_new + credit_num_general + credit_num_dpd + credit_num_danger\n",
    "    \n",
    "    data['average_minmob_percent_of_age'] = round(data[age_accounts].mean(axis = 1) / data['est_age'], 2)\n",
    "    data.loc[data['average_minmob_percent_of_age'] > 1, 'average_minmob_percent_of_age'] = 1\n",
    "    \n",
    "    data['average_percent_balance_total'] = round(data[percent_balance].sum(axis = 1) / 4, 1)\n",
    "    \n",
    "    data['credit_num_new'] = data[credit_num_new].sum(axis = 1)\n",
    "    data['credit_num_general'] = data[credit_num_general].sum(axis = 1)\n",
    "    data['credit_num_dpd'] = data[credit_num_dpd].sum(axis = 1)\n",
    "    data['credit_num_overage'] = data[credit_num_danger].sum(axis = 1)\n",
    "    \n",
    "    data['credit_hh_new_average'] = data[credit_hh_new].mean(axis = 1)\n",
    "    data['credit_hh_dpd_average'] = data[credit_hh_dpd].mean(axis = 1)\n",
    "    \n",
    "    data['credit_weighted_pct_dpd_overdue'] = 0.3 * data['credit_hh_totalallcredit_bankruptcy'] +\\\n",
    "                                              0.25 * data['credit_hh_totalallcredit_collections'] +\\\n",
    "                                              0.25 * data['credit_hh_totalallcredit_severederog'] +\\\n",
    "                                              0.2 * (data[credit_hh_dpd].sum(axis = 1))\n",
    "    \n",
    "    credit_all = credit_bal_general + credit_bal_dpd + credit_bal_overage + credit_bal_new\n",
    "    credit_bal_num = ['credit_num_new', 'credit_num_general', 'credit_num_dpd', 'credit_num_overage']\n",
    "    credit_total = data[credit_all].sum(axis = 1)\n",
    "    credit_num_total = data[credit_bal_num].sum(axis = 1)\n",
    "    \n",
    "    data['credit_weighted_pct_dpd_overdue'] = data['credit_weighted_pct_dpd_overdue'] / 100\n",
    "    \n",
    "    data['credit_financial_index'] = 0.075 * data[credit_bal_general].sum(axis = 1) / credit_total +\\\n",
    "                                       0.075 * data['credit_num_general'] / credit_num_total +\\\n",
    "                                       0.25 * data[credit_bal_dpd].sum(axis = 1) / credit_total +\\\n",
    "                                       0.05 * data['credit_num_dpd'] / credit_num_total +\\\n",
    "                                       0.30 * data[credit_bal_overage].sum(axis = 1) / credit_total +\\\n",
    "                                       0.10 * data['credit_num_overage'] / credit_num_total +\\\n",
    "                                       0.075 * data[credit_bal_new].sum(axis = 1) / credit_total +\\\n",
    "                                       0.075 * data['credit_num_new'] / credit_num_total     \n",
    "    data['credit_financial_index'] = (data['credit_financial_index'] - data['credit_financial_index'].min()) /\\\n",
    "                                      (data['credit_financial_index'].max() - data['credit_financial_index'].min())\n",
    "            \n",
    "    data['credit_total_new'] = data[credit_bal_new].sum(axis = 1)\n",
    "    data['credit_dpd_exposure'] = data['credit_num_dpd'] * data[credit_bal_dpd].sum(axis = 1)\n",
    "    data['credit_overage_exposure'] = data['credit_num_overage'] * data[credit_bal_overage].sum(axis = 1)\n",
    "    \n",
    "    data['default_risk'] = 0.2 * data['credit_dpd_exposure'] / np.log(credit_total + 1) +\\\n",
    "                            0.75 * data['credit_overage_exposure'] / np.log(credit_total + 1) +\\\n",
    "                            0.05 * data['credit_total_new'] / np.log(credit_total + 1) \n",
    "    data.loc[data['default_risk'] > 4, 'default_risk'] = 4\n",
    "    data['default_risk'] = (data['default_risk'] - data['default_risk'].min()) / (data['default_risk'].max() - data['default_risk'].min())\n",
    "    data['default_risk'].fillna(0, inplace = True)\n",
    "    \n",
    "    #Credit Balance Clustering Engineering\n",
    "    labels = range(1,21)\n",
    "    balance = []\n",
    "    for columns in credit_bal_clusters: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 20, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        balance.append(name)\n",
    "    pca = PCA(n_components = 12)\n",
    "    pc = pca.fit_transform(data[credit_bal_clusters])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_creditbal', 'PCA2_creditbal', 'PCA3_creditbal', \n",
    "                                                  'PCA4_creditbal', 'PCA5_creditbal', 'PCA6_creditbal',\n",
    "                                                  'PCA7_creditbal', 'PCA8_creditbal', 'PCA9_creditbal',\n",
    "                                                  'PCA10_creditbal', 'PCA11_creditbal', 'PCA12_creditbal'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "\n",
    "    data['Credit_Bal_Score'] = data[balance].sum(axis=1)\n",
    "    data['Credit_Bal_AVG_Score'] = data[balance].mean(axis=1)\n",
    "    data['Credit_Bal_Score'] = Standardize(data['Credit_Bal_Score'])\n",
    "    data['Credit_Bal_AVG_Score'] = Standardize(data['Credit_Bal_AVG_Score'])\n",
    "    data['default_risk_std'] = Standardize(data['default_risk'])\n",
    "    model_bal = cluster.KMeans(n_clusters = 30)\n",
    "    data['Credit_Bal_Score_clusters'] = model_bal.fit_predict(data[['Credit_Bal_Score', 'default_risk_std']])\n",
    "    \n",
    "    #Credit Number Clustering Engineering \n",
    "    number = []\n",
    "    for columns in credit_num_clusters: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 20, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        number.append(name)\n",
    "        \n",
    "    pca = PCA(n_components = 5)\n",
    "    pc = pca.fit_transform(data[credit_bal_clusters])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_creditnum', 'PCA2_creditnum', 'PCA3_creditnum', \n",
    "                                                  'PCA4_creditnum', 'PCA5_creditnum'])\n",
    "    \n",
    "    data['Credit_Num_Score'] = data[number].sum(axis=1)\n",
    "    data['Credit_Num_AVG_Score'] = data[number].mean(axis=1)\n",
    "    data['Credit_Num_Score'] = Standardize(data['Credit_Num_Score'])\n",
    "    data['Credit_Num_AVG_Score'] = Standardize(data['Credit_Num_AVG_Score'])\n",
    "    model_num = cluster.KMeans(n_clusters = 25)\n",
    "    data['Credit_Num_Score_clusters'] = model_num.fit_predict(data[['Credit_Num_Score', 'default_risk_std']])\n",
    "    \n",
    "    #Credit HH % Clustering Engineering\n",
    "    hh_percent = []\n",
    "    for columns in credit_hh_clusters: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 20, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        hh_percent.append(name)\n",
    "    pca = PCA(n_components = 7)\n",
    "    pc = pca.fit_transform(data[credit_bal_clusters])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_credithh', 'PCA2_credithh', 'PCA3_credithh', \n",
    "                                                  'PCA4_credithh', 'PCA5_credithh', 'PCA6_credithh',\n",
    "                                                  'PCA7_credithh'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    data['Credit_HH_Score'] = data[hh_percent].sum(axis=1)\n",
    "    data['Credit_HH_AVG_Score'] = data[hh_percent].mean(axis=1)\n",
    "    data['Credit_HH_Score'] = Standardize(data['Credit_HH_Score'])\n",
    "    data['Credit_HH_AVG_Score'] = Standardize(data['Credit_HH_AVG_Score'])\n",
    "    model_hh = cluster.KMeans(n_clusters = 25)\n",
    "    data['Credit_HH_Score_clusters'] = model_hh.fit_predict(data[['Credit_HH_Score', 'default_risk_std']])\n",
    "\n",
    "    credit = age_accounts + percent_balance + credit_bal_clusters +\\\n",
    "    credit_num_clusters + ['default_risk_std'] + credit_hh_clusters\n",
    "    \n",
    "    for column in credit:\n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6X3iGaKdT46"
   },
   "outputs": [],
   "source": [
    "def FillNaN(data):\n",
    "    '''\n",
    "    Fills all NAN values based on certain criteria \n",
    "    \n",
    "    Takes one input:\n",
    "    data: a pandas dataframe\n",
    "    \n",
    "    Returns dataframe with all NAN values filled (which aren't tied to another function)\n",
    "    '''\n",
    "    data['cms_ma_risk_score_nbr'].fillna(data['cms_ma_risk_score_nbr'].mean(), inplace = True)\n",
    "    data['cms_partd_ra_factor_amt'].fillna(data['cms_partd_ra_factor_amt'].mean(), inplace = True)\n",
    "    data['cms_risk_adj_payment_rate_a_amt'].fillna(data['cms_risk_adj_payment_rate_a_amt'].mean(), inplace = True)\n",
    "    data['cms_risk_adj_payment_rate_b_amt'].fillna(data['cms_risk_adj_payment_rate_b_amt'].mean(), inplace = True)\n",
    "    data['cms_risk_adjustment_factor_a_amt'].fillna(data['cms_risk_adjustment_factor_a_amt'].mean(), inplace = True)\n",
    "    data['cms_rx_risk_score_nbr'].fillna(data['cms_rx_risk_score_nbr'].mean(), inplace = True)\n",
    "    data['cms_tot_ma_payment_amt'].fillna(data['cms_tot_ma_payment_amt'].mean(), inplace = True)\n",
    "    data['cms_tot_partd_payment_amt'].fillna(data['cms_tot_partd_payment_amt'].mean(), inplace = True)\n",
    "    \n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trqjRIq9dT49"
   },
   "outputs": [],
   "source": [
    "def CMSEngineering(data): \n",
    "    '''\n",
    "    Creates new features based on CMS Risk Adjusted Information information\n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "\n",
    "    data['cms_risk_ma_nbr_rx_combined'] = data['cms_ma_risk_score_nbr'] * data['cms_rx_risk_score_nbr'] / 2 * (data['cms_ma_risk_score_nbr'] + data['cms_rx_risk_score_nbr'])\n",
    "    data['reverse_raf'] = data['cms_risk_adjustment_factor_a_amt'] / (1 + data['hcc_weighted_sum'])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShBWhV4MdT5B"
   },
   "outputs": [],
   "source": [
    "def healthFactorsEngineering(data): \n",
    "    '''\n",
    "    Creates new features based on some of the health scoring metrics\n",
    "\n",
    "    Takes one input:\n",
    "    data: a pandas data frame\n",
    "    \n",
    "    Returns a pandas dataframe with new updated columns\n",
    "    '''\n",
    "    cms_numeric_data = ['cms_partd_ra_factor_amt',\n",
    "                        'cms_risk_adj_payment_rate_a_amt',\n",
    "                        'cms_risk_adj_payment_rate_b_amt',\n",
    "                        'cms_risk_adjustment_factor_a_amt',\n",
    "                        'cms_tot_ma_payment_amt']\n",
    "    \n",
    "    data['life_remain'] = (67.98999 + data['sex_cd'] * 5 + (data['est_age'] * -0.67718)) * ((-6.51961 * data['cci_score'] + 104.04545) / 100)\n",
    "    \n",
    "    data['cci_score'] = (data['cci_score'] - data['cci_score'].min()) / (data['cci_score'].max() - data['cci_score'].min())\n",
    "    data['dcsi_score'] = (data['dcsi_score'] - data['dcsi_score'].min()) / (data['dcsi_score'].max() - data['dcsi_score'].min())\n",
    "    data['fci_score'] = (data['fci_score'] - data['fci_score'].min()) / (data['fci_score'].max() - data['fci_score'].min())\n",
    "    data['hcc_weighted_sum'] = (data['hcc_weighted_sum'] - data['hcc_weighted_sum'].min()) / (data['hcc_weighted_sum'].max() - data['hcc_weighted_sum'].min())\n",
    "\n",
    "    data['weighted_three_scores'] = data['fci_score'] * .40 + data['cci_score'] * .40  + data['dcsi_score'] * .20\n",
    "    data['weighted_full_health']= data['fci_score'] * .25 + data['cci_score'] * .25  + data['dcsi_score'] * .25 + data['hcc_weighted_sum'] * 0.25\n",
    "    \n",
    "    pca = PCA(n_components = 2)\n",
    "    pc = pca.fit_transform(data[cms_numeric_data])\n",
    "    \n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_cms', 'PCA2_cms'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    labels = range(1,51)\n",
    "    cms = []\n",
    "    for columns in cms_numeric_data: \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 50, labels = labels)\n",
    "        cms.append(name)\n",
    "        data[name] = data[name].astype(int)\n",
    "    \n",
    "    data['CMS_Score'] = data[cms].sum(axis=1)\n",
    "    data['CMS_AVG_Score'] = data[cms].mean(axis=1)\n",
    "    data['CMS_Score'] = Standardize(data['CMS_Score'])\n",
    "    data['CMS_AVG_Score'] = Standardize(data['CMS_AVG_Score'])\n",
    "    data['weighted_full_health_std'] = Standardize(data['weighted_full_health'])\n",
    "\n",
    "    model_cms = cluster.KMeans(n_clusters = 20)\n",
    "    data['CMS_Score_clusters'] = model_cms.fit_predict(data[['CMS_Score', 'weighted_full_health_std']])\n",
    "    \n",
    "    cms_numeric_data += ['weighted_full_health_std']\n",
    "    \n",
    "    for cms_numeric in cms_numeric_data:\n",
    "        data.drop(cms_numeric, inplace = True, axis = 1)\n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E3SGjaaIdT5E"
   },
   "outputs": [],
   "source": [
    "def DummyVariables(data): \n",
    "    '''\n",
    "    Creates dummy variable columns for all categorical data\n",
    "    \n",
    "    Takes two argument:\n",
    "    \n",
    "    data: A pandas dataframe (with categorical variables)\n",
    "    drop: boolean value whether dropfirst is true\n",
    "    \n",
    "    Returns a pandas data frame with \n",
    "    '''\n",
    "    data = data.set_index('person_id_syn')\n",
    "    data = pd.get_dummies(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2qSTDfjXdT5K"
   },
   "outputs": [],
   "source": [
    "def MobilityandStressIndex(data):\n",
    "    '''\n",
    "    Creates two new weighted index scores from the financial, health, and demogaphic data provided.\n",
    "    (Must be run after dummy variables are created)\n",
    "    \n",
    "    Takes one input: \n",
    "    data: a pandas data frame \n",
    "    \n",
    "    Returns a pandas dataframe with two new index scores\n",
    "    '''\n",
    "    \n",
    "    dummy_columns_to_drop  = ['cms_ra_factor_type_cd_Unknown','cons_cmys_Unknown',\n",
    "                             'cons_hhcomp_Unknown', 'cons_homstat_Unknown']\n",
    "    \n",
    "    \n",
    "    data['MobilityIndex'] = 0.2021 * data['cms_disabled_ind'] + 0.1295 * data['est_age'] / data['est_age'].max() +\\\n",
    "                        0.1062 * data['life_remain'] / data['life_remain'].max() + 0.0586 * data['credit_financial_index'] +\\\n",
    "                        0.0725 * data['cons_n65p_y'] + 0.0572 * data['cms_low_income_ind'] + 0.034 * data['cons_n2pmv'] +\\\n",
    "                        0.151 * data['weighted_full_health'] + data['hlth_pgm_slvrsnkr_par_status'] * -0.03 +\\\n",
    "                        0.1207 * (9 - data['rucc_category']) + 0.1364 * data['cons_hhcomp_Min Two People, Children'] +\\\n",
    "                        0.00521 * data['cons_hhcomp_Min Two People, No Children'] + 0.0682 * data['cons_hhcomp_One Person, Children']+\\\n",
    "                        0.02728 * data['cons_hhcomp_One Person, No Children'] + 0.0492 * data['cons_hhcomp_Unknown']\n",
    "    data['MobilityIndex'] = (data['MobilityIndex'] - data['MobilityIndex'].min()) /\\\n",
    "                            (data['MobilityIndex'].max() - data['MobilityIndex'].min())\n",
    "    \n",
    "    \n",
    "    data['StressIndex'] = 0.027 * data['cons_veteran_y'] + 0.1517 * data['credit_financial_index'] +\\\n",
    "                      0.0385 * data['cons_n65p_y'] + 0.1326 * data['cms_low_income_ind'] +\\\n",
    "                      0.2243 * data['default_risk'] + 0.0293 * data['smoker_current_ind'] +\\\n",
    "                      0.0783 * data['submcc_men_alco_ind'] + 0.0921 * data['submcc_men_depr_ind'] +\\\n",
    "                      0.0894 * data['submcc_men_abus_ind'] + 0.0868 * data['cons_hhcomp_Min Two People, Children'] +\\\n",
    "                      0.05872 * data['cons_hhcomp_Min Two People, No Children'] + 0.1468 * data['cons_hhcomp_One Person, Children']+\\\n",
    "                      0.02936 * data['cons_hhcomp_One Person, No Children'] + 0.08808 * data['cons_hhcomp_Unknown']\n",
    "    \n",
    "    \n",
    "    data['StressIndex'] = (data['StressIndex'] - data['StressIndex'].min()) /\\\n",
    "                            (data['StressIndex'].max() - data['StressIndex'].min())\n",
    "    data['est_age'] = np.log(data['est_age'])\n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    for dummy in dummy_columns_to_drop:\n",
    "        data.drop(dummy, inplace = True, axis = 1)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJo_UjiLdT5N"
   },
   "outputs": [],
   "source": [
    "def hospitalEngineering(data):\n",
    "    '''\n",
    "    Drops all the columns related to hospital visits that have 0 values\n",
    "    Add two columns: \n",
    "    \n",
    "    1. total_emer_visits\n",
    "    2. total_admit_days\n",
    "    \n",
    "    Drops all the admit days after summing them into the total_admit_days column\n",
    "    \n",
    "    One input: DataFrame\n",
    "    '''\n",
    "    data.drop(columns = ['total_ip_ltach_admit_ct_pmpm','total_ip_ltach_admit_days_pmpm','total_ip_maternity_admit_ct_pmpm'\n",
    "                         ,'total_ip_maternity_admit_days_pmpm'],inplace = True)\n",
    "\n",
    "    data['total_emer_visits'] = data['total_ambulance_visit_ct_pmpm'] + data['total_er_visit_ct_pmpm']\n",
    "\n",
    "    data['total_admit_days'] = data['total_ip_acute_admit_days_pmpm'] + data['total_ip_mhsa_admit_days_pmpm'] +\\\n",
    "                               data['total_ip_rehab_admit_days_pmpm'] + data['total_ip_snf_admit_days_pmpm']\n",
    "    \n",
    "    data.drop(['total_ip_acute_admit_days_pmpm','total_ip_mhsa_admit_days_pmpm','total_ip_rehab_admit_days_pmpm',\n",
    "              'total_ip_snf_admit_days_pmpm'], axis = 1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ImxUkIv9dT5S"
   },
   "outputs": [],
   "source": [
    "def RxEngineering(data):\n",
    "    '''\n",
    "    Creates two new weighted index scores from the financial, health, and demogaphic data provided.\n",
    "    (Must be run after dummy variables are created)\n",
    "    \n",
    "    Takes one input: \n",
    "    data: a pandas data frame \n",
    "    \n",
    "    Returns a pandas dataframe with two new index scores\n",
    "    '''\n",
    "\n",
    "\n",
    "    \n",
    "    rx_columns = ((data.filter(like=\"rx\", axis=1).columns)&(data.filter(like=\"pmpm_ct\", axis=1).columns)).tolist()\n",
    "\n",
    "    pca = PCA(n_components = 5)\n",
    "    pc = pca.fit_transform(data[rx_columns])\n",
    "\n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_rx', 'PCA2_rx', 'PCA3_rx', \n",
    "                                                  'PCA4_rx', 'PCA5_rx'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    labels = range(1,51)\n",
    "    rx_list = []\n",
    "    for columns in rx_columns : \n",
    "        name = columns + \"_rank\"\n",
    "        data[name] = pd.qcut(data[columns].rank(method = 'first'), q = 50, labels = labels)\n",
    "        data[name] = data[name].astype(int)\n",
    "        rx_list.append(name)\n",
    "    \n",
    "    data['RX_Score'] = data[rx_list].sum(axis=1)\n",
    "    data['RX_AVG_Score'] = data[rx_list].mean(axis=1)\n",
    "    data['RX_Score'] = Standardize(data['RX_Score'])\n",
    "    data['RX_AVG_Score'] = Standardize(data['RX_AVG_Score'])\n",
    "    model_rx = cluster.KMeans(n_clusters = 25)\n",
    "    data['RX_Score_clusters'] = model_rx.fit_predict(data[['RX_Score', 'est_age_std']])\n",
    "    \n",
    "    for rx in rx_columns:\n",
    "        data.drop(rx, inplace = True, axis = 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DLBqRcVYdT5U"
   },
   "outputs": [],
   "source": [
    "# finalize into a function \n",
    "def EngineerSUBMCC_PMPMcolumns(data):\n",
    "    \"\"\"\n",
    "    Groups the SUBMCC PMPM columns\n",
    "    \n",
    "    One Inputs:\n",
    "    \n",
    "    data: a pandas dataframe\n",
    "    \n",
    "    Returns pandas DataFrame with updated columns to replace for all submcc_pmpm_ct \n",
    "    \"\"\"\n",
    "\n",
    "    # drop _ano, _inf, _pre, _hiv, _trm; keep 23 mcc_pmpm columns\n",
    "    mcc_list = [ \"_ben\", \"_bld\", \"_brn\", \"_cad\", \"_can\", \"_cer\", \"_cir\", \"_dia\", \n",
    "                \"_dig\", \"_end\", \"_gus\", \"_hdz\", \"_inj\",\"_men\", \"_mus\", \"_ner\",\"_rar\", \"_res\", \"_rsk\", \"_skn\", \"_sns\", \"_sor\", \"_vco\"]\n",
    "\n",
    "    labels = range(1,21)\n",
    "    submcc_list = []\n",
    "    for mcc in mcc_list:\n",
    "        count = 'count' + mcc \n",
    "        data[count] = data[(data.filter(like=mcc, axis=1).columns) & (data.filter(like=\"pmpm_ct\", axis=1).columns)].sum(axis=1)\n",
    "        name = count + \"_rank\"\n",
    "        data[name] = pd.qcut(data[count].rank(method = 'first'), q = 20, labels = labels)\n",
    "        submcc_list.append(name)\n",
    "        data[name] = data[name].astype(int)\n",
    "        \n",
    "\n",
    "    columns = ((data.filter(like=\"submcc\", axis=1).columns)&(data.filter(like=\"pmpm_ct\", axis=1).columns)).tolist()\n",
    "    \n",
    "    pca = PCA(n_components = 30)\n",
    "    pc = pca.fit_transform(data[columns])\n",
    "    \n",
    "    pca_data = pd.DataFrame(data = pc, columns = ['PCA1_submcc', 'PCA2_submcc', 'PCA3_submcc', \n",
    "                                                  'PCA4_submcc', 'PCA5_submcc', 'PCA6_submcc',\n",
    "                                                  'PCA7_submcc', 'PCA8_submcc', 'PCA9_submcc',\n",
    "                                                  'PCA10_submcc', 'PCA11_submcc', 'PCA12_submcc', \n",
    "                                                  'PCA13_submcc', 'PCA14_submcc', 'PCA15_submcc', \n",
    "                                                  'PCA16_submcc', 'PCA17_submcc', 'PCA18_submcc',\n",
    "                                                  'PCA19_submcc', 'PCA20_submcc', 'PCA21_submcc',\n",
    "                                                  'PCA22_submcc', 'PCA23_submcc', 'PCA24_submcc', \n",
    "                                                  'PCA25_submcc', 'PCA26_submcc', 'PCA27_submcc', \n",
    "                                                  'PCA28_submcc', 'PCA29_submcc', 'PCA30_submcc'])\n",
    "    data = pd.concat([data, pca_data], axis = 1)\n",
    "    \n",
    "    data['SUBMCC_Score'] = data[submcc_list].sum(axis=1)\n",
    "    data['SUBMCC_AVG_Score'] = data[submcc_list].mean(axis=1)\n",
    "    data['SUBMCC_Score'] = Standardize(data['SUBMCC_Score'])\n",
    "    data['SUBMCC_AVG_Score'] = Standardize(data['SUBMCC_AVG_Score'])\n",
    "    data['est_age_std'] = Standardize(data['est_age'])\n",
    "    model_submcc = cluster.KMeans(n_clusters = 30)\n",
    "    data['SUBMCC_Score_clusters'] = model_submcc.fit_predict(data[['SUBMCC_Score', 'est_age_std']])\n",
    "    \n",
    "    for column in columns: \n",
    "        data.drop(column, inplace = True, axis = 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlOQqb-cdT5Z"
   },
   "outputs": [],
   "source": [
    "def NormalizeMaxMin(data, columnname):\n",
    "    \n",
    "    data[columnname] = (data[columnname] - data[columnname].min()) /\\\n",
    "    (data[columnname].max() - data[columnname].min())\n",
    "    \n",
    "    return data[columnname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwQWeAR-dT5c"
   },
   "outputs": [],
   "source": [
    "def Standardize(data):\n",
    "    data = (data - data.mean()) / data.std()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lFIVsOoDdT5e",
    "outputId": "858001eb-9fcf-4c17-fdc8-011f36420937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped:  hedis_ami\n",
      "Dropped:  hedis_cmc_ldc_c_control\n",
      "Dropped:  hedis_cmc_ldc_c_screen\n"
     ]
    }
   ],
   "source": [
    "health = mapStringVariables(health)\n",
    "health = dropMajorityNAcolumns(health)\n",
    "health = FillNaN(health)\n",
    "health = columnBinning(health)\n",
    "health = columnsToDrop(health)\n",
    "health = LabelEncoding(health)\n",
    "health = betosEngineering(health)\n",
    "health = medEngineering(health)\n",
    "health = creditDataEngineering(health)\n",
    "health = CMSEngineering(health)\n",
    "health = healthFactorsEngineering(health)\n",
    "health = hospitalEngineering(health)\n",
    "health = EngineerSUBMCC_PMPMcolumns(health)\n",
    "health = RxEngineering(health)\n",
    "health = DummyVariables(health)\n",
    "health = MobilityandStressIndex(health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDKmCZf1dT5i",
    "outputId": "fb318c41-90c5-44cb-ba61-efd4d66e42a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69572, 752)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "health.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdBvsoPldT5l"
   },
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "#health.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i_U57k2edT5o"
   },
   "outputs": [],
   "source": [
    "#cluster_analysis = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nDZ6upxzdT5r"
   },
   "outputs": [],
   "source": [
    "#data = health.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ykwOv8uDdT5v"
   },
   "outputs": [],
   "source": [
    "#data['Credit_Bal_Score'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pQDPL3s2dT5z"
   },
   "outputs": [],
   "source": [
    "#data['MobilityIndex_std'] = Standardize(data['MobilityIndex'])\n",
    "#data['StressIndex_std'] = Standardize(data['StressIndex'])\n",
    "#data['default_risk_std'] = Standardize(data['default_risk'])\n",
    "#data['est_age_std'] = Standardize(data['est_age'])\n",
    "#data['credit_financial_index_std'] = Standardize(data['credit_financial_index'])\n",
    "#data['life_remain_std'] = Standardize(data['life_remain'])\n",
    "#data['reverse_raf_std'] = Standardize(data['reverse_raf'])\n",
    "#data['Credit_Bal_Score_clusters_std'] = Standardize(data['Credit_Bal_Score_clusters'])\n",
    "#data['Credit_Num_Score_clusters_std'] = Standardize(data['Credit_Num_Score_clusters'])\n",
    "#data['Credit_HH_Score_clusters_std'] = Standardize(data['Credit_HH_Score_clusters'])\n",
    "#data['SUBMCC_Score_clusters_std'] = Standardize(data['SUBMCC_Score_clusters'])\n",
    "#data['RX_Score_clusters_std'] = Standardize(data['RX_Score_clusters'])\n",
    "#data['Betos_Score_clusters_std'] = Standardize(data['Betos_Score_clusters'])\n",
    "#data['clusters_std'] = Standardize(data['clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TWovVZ1odT53"
   },
   "outputs": [],
   "source": [
    "#columns = ((data.filter(like=\"cluster\", axis=1).columns)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7jJzgNtdT57"
   },
   "outputs": [],
   "source": [
    "#ss = []\n",
    "#for i in range(2, 40):\n",
    "#    model_mobstress = cluster.KMeans(n_clusters = i)\n",
    "#    model_mobstress.fit_predict(data[['Credit_Bal_Score', 'StressIndex_std']])\n",
    "#    ss.append(model_mobstress.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkspPYNMdT59"
   },
   "outputs": [],
   "source": [
    "#plot the elbow plot\n",
    "#data1 = pd.DataFrame({'K': range(2, 40),\n",
    "#                     'Sum of Squares': ss})\n",
    "#sns.lineplot(data = data1,\n",
    "#            x = 'K',\n",
    "#            y = 'Sum of Squares')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7wu0RA0dT6A"
   },
   "outputs": [],
   "source": [
    "#model = cluster.KMeans(n_clusters = 15)\n",
    "#data['clusters'] = model.fit_predict(data[['Credit_Bal_Score', 'StressIndex_std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWuq_dQKdT6J"
   },
   "outputs": [],
   "source": [
    "#cluster1 = data[data['transportation_issues'] == 1]\n",
    "#cluster2 = data[data['transportation_issues'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-Kjny6EdT6L"
   },
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(2, 1, figsize = (20, 20))\n",
    "#sns.scatterplot(data = cluster1,\n",
    "#                   x = 'Credit_Bal_Score',\n",
    "#                  y = 'StressIndex_std',\n",
    "#                  hue = 'clusters',\n",
    "#                   palette = 'bright', ax = ax[0])\n",
    "#sns.scatterplot(data = cluster2,\n",
    "#                   x = 'Credit_Bal_Score',\n",
    "#                   y = 'StressIndex_std',\n",
    "#                   hue = 'clusters',\n",
    "#                   palette = 'bright', ax = ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x5xYMeIkdT6N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "criz3r6sdT6Q"
   },
   "outputs": [],
   "source": [
    "#from sklearn import cluster\n",
    "#from sklearn.decomposition import PCA\n",
    "#labels = range(1,21)\n",
    "#balance = []\n",
    "#for columns in cms_numeric_data: \n",
    "#    name = columns + \"_rank\"\n",
    "#    cluster_analysis[name] = pd.qcut(cluster_analysis[columns].rank(method = 'first'), q = 20, labels = labels)\n",
    "#    balance.append(name)\n",
    "#pca_data = pd.DataFrame(data = pc, columns = ['PCA1_creditnum', 'PCA2_creditnum', 'PCA3_creditnum', \n",
    "         #                                     'PCA4_creditnum', 'PCA5_creditnum', 'PCA6_creditnum',\n",
    "         #                                     'PCA7_creditnum', 'PCA8_creditnum', 'PCA9_creditnum',\n",
    "          #                                    'PCA10_creditnum', 'PCA11_creditnum', 'PCA12_creditnum'])\n",
    "#cluster_analysis = pd.concat([cluster_analysis, pca_data], axis = 1)\n",
    "#cluster_analysis['RX_Score'] = cluster_analysis[values].sum(axis=1)\n",
    "#cluster_analysis['RX_Score'] = Standardize(cluster_analysis['RX_Score'])\n",
    "\n",
    "#model_bal = cluster.KMeans(n_clusters = 30)\n",
    "#model_num.fit_predict(cluster_analysis[['SUBMCC_Score', 'est_age_std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSH8fSdidT6T"
   },
   "outputs": [],
   "source": [
    "#pca = PCA(n_components = 5)\n",
    "#pc = pca.fit_transform(cluster_analysis[credit_num_clusters])\n",
    "\n",
    "#sum(pca.explained_variance_ratio_)\n",
    "#pca_data = pd.DataFrame(data = pc, columns = ['PCA1_creditnum', 'PCA2_creditnum', 'PCA3_creditnum', \n",
    "         #                                     'PCA4_creditnum', 'PCA5_creditnum', 'PCA6_creditnum',\n",
    "         #                                     'PCA7_creditnum', 'PCA8_creditnum', 'PCA9_creditnum',\n",
    "          #                                    'PCA10_creditnum', 'PCA11_creditnum', 'PCA12_creditnum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWJ84n1ydT6V"
   },
   "outputs": [],
   "source": [
    "health.to_csv('data/new_cleaned_trainingdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z8M0TuLSdT6X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kfv7oYHvdT6b"
   },
   "outputs": [],
   "source": [
    "def RxEngineeringDead(data):\n",
    "    '''\n",
    "    Creates two new weighted index scores from the financial, health, and demogaphic data provided.\n",
    "    (Must be run after dummy variables are created)\n",
    "    \n",
    "    Takes one input: \n",
    "    data: a pandas data frame \n",
    "    \n",
    "    Returns a pandas dataframe with two new index scores\n",
    "    '''\n",
    "    \n",
    "    common_rx = ['rx_gpi2_01_pmpm_ct','rx_gpi2_02_pmpm_ct','rx_gpi2_03_pmpm_ct','rx_gpi2_04_pmpm_ct','rx_gpi2_05_pmpm_ct','rx_gpi2_08_pmpm_ct',\n",
    "              'rx_gpi2_11_pmpm_ct', 'rx_gpi2_12_pmpm_ct','rx_gpi2_17_pmpm_ct','rx_gpi2_18_pmpm_ct','rx_gpi2_25_pmpm_ct','rx_gpi2_26_pmpm_ct',\n",
    "              'rx_gpi2_27_pmpm_ct','rx_gpi2_29_pmpm_ct','rx_gpi2_30_pmpm_ct','rx_gpi2_37_pmpm_ct','rx_gpi2_39_pmpm_ct','rx_gpi2_41_pmpm_ct',\n",
    "              'rx_gpi2_42_pmpm_ct','rx_gpi2_43_pmpm_ct','rx_gpi2_44_pmpm_ct','rx_gpi2_45_pmpm_ct','rx_gpi2_46_pmpm_ct','rx_gpi2_47_pmpm_ct',\n",
    "              'rx_gpi2_48_pmpm_ct','rx_gpi2_49_pmpm_ct','rx_gpi2_50_pmpm_ct','rx_gpi2_51_pmpm_ct','rx_gpi2_52_pmpm_ct', 'rx_gpi2_53_pmpm_ct',\n",
    "              'rx_gpi2_54_pmpm_ct','rx_gpi2_55_pmpm_ct','rx_gpi2_56_pmpm_ct','rx_gpi2_57_pmpm_ct','rx_gpi2_58_pmpm_ct','rx_gpi2_59_pmpm_ct',\n",
    "              'rx_gpi2_60_pmpm_ct','rx_gpi2_61_pmpm_ct','rx_gpi2_62_pmpm_ct','rx_gpi2_64_pmpm_ct','rx_gpi2_65_pmpm_ct','rx_gpi2_66_pmpm_ct',\n",
    "              'rx_gpi2_67_pmpm_ct','rx_gpi2_69_pmpm_ct','rx_gpi2_70_pmpm_ct','rx_gpi2_72_pmpm_ct','rx_gpi2_73_pmpm_ct','rx_gpi2_74_pmpm_ct',\n",
    "              'rx_gpi2_75_pmpm_ct','rx_gpi2_77_pmpm_ct','rx_gpi2_78_pmpm_ct', 'rx_gpi2_79_pmpm_ct','rx_gpi2_80_pmpm_ct','rx_gpi2_81_pmpm_ct',\n",
    "              'rx_gpi2_84_pmpm_ct','rx_gpi2_85_pmpm_ct','rx_gpi2_86_pmpm_ct','rx_gpi2_87_pmpm_ct','rx_gpi2_88_pmpm_ct','rx_gpi2_89_pmpm_ct',\n",
    "              'rx_gpi2_92_pmpm_ct','rx_gpi2_93_pmpm_ct','rx_gpi2_94_pmpm_ct','rx_gpi2_95_pmpm_ct','rx_gpi2_96_pmpm_ct','rx_gpi2_97_pmpm_ct',\n",
    "              'rx_gpi2_99_pmpm_ct', 'rx_gpi2_90_pmpm_ct', 'rx_gpi2_98_pmpm_ct']\n",
    "    \n",
    "    tired_rx = ['rx_gpi2_08_pmpm_ct','rx_gpi2_09_pmpm_ct','rx_gpi2_17_pmpm_ct','rx_gpi2_18_pmpm_ct','rx_gpi2_19_pmpm_ct','rx_gpi2_21_pmpm_ct',\n",
    "                'rx_gpi2_28_pmpm_ct', 'rx_gpi2_33_pmpm_ct','rx_gpi2_34_pmpm_ct','rx_gpi2_41_pmpm_ct','rx_gpi2_43_pmpm_ct','rx_gpi2_44_pmpm_ct',\n",
    "                'rx_gpi2_50_pmpm_ct','rx_gpi2_54_pmpm_ct','rx_gpi2_57_pmpm_ct','rx_gpi2_59_pmpm_ct','rx_gpi2_61_pmpm_ct','rx_gpi2_65_pmpm_ct',\n",
    "                'rx_gpi2_67_pmpm_ct','rx_gpi2_72_pmpm_ct','rx_gpi2_82_pmpm_ct','rx_gpi2_89_pmpm_ct']\n",
    "    \n",
    "    severe_rx = ['rx_gpi2_07_pmpm_ct','rx_gpi2_21_pmpm_ct','rx_gpi2_31_pmpm_ct','rx_gpi2_32_pmpm_ct','rx_gpi2_33_pmpm_ct','rx_gpi2_34_pmpm_ct',\n",
    "                 'rx_gpi2_36_pmpm_ct', 'rx_gpi2_38_pmpm_ct','rx_gpi2_40_pmpm_ct','rx_gpi2_83_pmpm_ct']\n",
    "    \n",
    "    motorability = ['rx_gpi2_01_pmpm_ct','rx_gpi2_02_pmpm_ct','rx_gpi2_03_pmpm_ct','rx_gpi2_04_pmpm_ct','rx_gpi2_07_pmpm_ct','rx_gpi2_08_pmpm_ct',\n",
    "                'rx_gpi2_12_pmpm_ct', 'rx_gpi2_13_pmpm_ct','rx_gpi2_15_pmpm_ct','rx_gpi2_16_pmpm_ct','rx_gpi2_21_pmpm_ct','rx_gpi2_22_pmpm_ct',\n",
    "                'rx_gpi2_28_pmpm_ct','rx_gpi2_29_pmpm_ct','rx_gpi2_31_pmpm_ct','rx_gpi2_32_pmpm_ct','rx_gpi2_34_pmpm_ct','rx_gpi2_35_pmpm_ct',\n",
    "                'rx_gpi2_36_pmpm_ct','rx_gpi2_37_pmpm_ct','rx_gpi2_38_pmpm_ct','rx_gpi2_39_pmpm_ct','rx_gpi2_41_pmpm_ct','rx_gpi2_44_pmpm_ct',\n",
    "                'rx_gpi2_45_pmpm_ct','rx_gpi2_50_pmpm_ct','rx_gpi2_51_pmpm_ct','rx_gpi2_52_pmpm_ct','rx_gpi2_53_pmpm_ct', 'rx_gpi2_54_pmpm_ct',\n",
    "                'rx_gpi2_57_pmpm_ct','rx_gpi2_58_pmpm_ct','rx_gpi2_59_pmpm_ct','rx_gpi2_60_pmpm_ct','rx_gpi2_61_pmpm_ct','rx_gpi2_62_pmpm_ct',\n",
    "                'rx_gpi2_65_pmpm_ct','rx_gpi2_67_pmpm_ct','rx_gpi2_68_pmpm_ct','rx_gpi2_72_pmpm_ct','rx_gpi2_73_pmpm_ct','rx_gpi2_75_pmpm_ct',\n",
    "                'rx_gpi2_76_pmpm_ct','rx_gpi2_79_pmpm_ct','rx_gpi2_82_pmpm_ct','rx_gpi2_83_pmpm_ct','rx_gpi2_84_pmpm_ct','rx_gpi2_89_pmpm_ct',\n",
    "                'rx_gpi2_93_pmpm_ct']\n",
    "    \n",
    "    data['rx_common_total'] = data[common_rx].sum(axis = 1)\n",
    "    data['rx_common_total_pct'] = data['rx_common_total'] / (data['rx_overall_pmpm_ct'] + 1)\n",
    "    data['rx_common_total_pct'] = NormalizeMaxMin(data, 'rx_common_total_pct')\n",
    "    data['rx_tired_total'] = data[common_rx].sum(axis = 1)\n",
    "    data['rx_tired_total_pct'] = data['rx_tired_total'] / (data['rx_overall_pmpm_ct'] + 1)\n",
    "    data['rx_tired_total_pct'] = NormalizeMaxMin(data, 'rx_tired_total_pct')\n",
    "    data['rx_severe_total'] = data[common_rx].sum(axis = 1)\n",
    "    data['rx_severe_total_pct'] = data['rx_severe_total'] / (data['rx_overall_pmpm_ct'] + 1)\n",
    "    data['rx_severe_total_pct'] = NormalizeMaxMin(data, 'rx_severe_total_pct')\n",
    "    data['rx_motorability_total'] = data[common_rx].sum(axis = 1)\n",
    "    data['rx_motorability_total_pct'] = data['rx_motorability_total'] / (data['rx_overall_pmpm_ct'] + 1)\n",
    "    data['rx_motorability_total_pct'] = NormalizeMaxMin(data, 'rx_motorability_total_pct')\n",
    "    \n",
    "    data['RxMobileIndex'] = data['rx_overall_pmpm_ct'] * (data['rx_common_total_pct'] * 0.075 +\\\n",
    "                                                                    data['rx_tired_total_pct'] * 0.25 +\\\n",
    "                                                                    data['rx_severe_total_pct'] * 0.375 +\\\n",
    "                                                                    data['rx_motorability_total_pct'] * 0.3)\n",
    "    data['RxMobileIndex'] = (data['RxMobileIndex'] - data['RxMobileIndex'].min()) /\\\n",
    "                            (data['RxMobileIndex'].max() - data['RxMobileIndex'].min())\n",
    "    data['RxMobileIndex_pct'] = (data['rx_common_total_pct'] * 0.075 +\\\n",
    "                                 data['rx_tired_total_pct'] * 0.25 +\\\n",
    "                                 data['rx_severe_total_pct'] * 0.375 +\\\n",
    "                                 data['rx_motorability_total_pct'] * 0.3)\n",
    "    \n",
    "    columns = ((data.filter(like=\"submcc\", axis=1).columns)&(data.filter(like=\"pmpm_ct\", axis=1).columns)).tolist()\n",
    "    \n",
    "    for rx in list(set(rx_all)):\n",
    "        data.drop(rx, inplace = True, axis = 1)\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Final_FeatureEngineering.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
